{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12b41378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4211e823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 2, 1],\n",
      "         [2, 2, 2, 2],\n",
      "         [2, 0, 1, 1]],\n",
      "\n",
      "        [[2, 1, 2, 1],\n",
      "         [0, 1, 1, 0],\n",
      "         [2, 1, 1, 0]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[999, 999, 999, 999],\n",
       "         [999, 999, 999, 999],\n",
       "         [999,   0, 999, 999]],\n",
       "\n",
       "        [[999, 999, 999, 999],\n",
       "         [  0, 999, 999,   0],\n",
       "         [999, 999, 999,   0]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic\n",
    "torch.tensor([4, 5, 6])\n",
    "torch.from_numpy(np.array([7, 8, 9]))\n",
    "torch.zeros(8, 8)\n",
    "torch.ones(3, 8)\n",
    "torch.randn(3, 8)\n",
    "torch.randint(0, 21, (8, 8))\n",
    "torch.rand(8, 8)\n",
    "torch.randperm(8)\n",
    "torch.eye(8)\n",
    "torch.full((2, 4), 8)\n",
    "torch.empty(2, 4)\n",
    "torch.arange(0, 10, 3)\n",
    "torch.linspace(0, 9, 9)\n",
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "x * y\n",
    "x / y\n",
    "x ** 2\n",
    "x % 2\n",
    "x.add_(1)\n",
    "torch.mm(x, y.t()) # 2d\n",
    "torch.matmul(x, y.t())\n",
    "m = torch.randn(2, 3, 4)\n",
    "n = torch.randn(2, 4, 3)\n",
    "torch.matmul(m, n)\n",
    "x @ y.t()\n",
    "torch.bmm(m, n) # 3d\n",
    "x = torch.randn(2, 1)\n",
    "y = torch.randn(1, 2)\n",
    "\n",
    "x = torch.tensor([1, 2])  # 1D 张量 (2,)\n",
    "y = torch.tensor([3, 4])  # 1D 张量 (2,)\n",
    "y_t = y.t()  # 1D 转置仍为 (2,)\n",
    "\n",
    "torch.einsum('i,j->ij', x, y_t)\n",
    "# # like\n",
    "# x = torch.randint(0, 3, (2, 3, 4))\n",
    "# torch.zeros_like(x)\n",
    "# torch.rand_like(x)\n",
    "\n",
    "# math\n",
    "x = torch.randint(0, 3, (2, 3, 4))\n",
    "torch.abs(x)\n",
    "torch.sqrt(abs(x))\n",
    "torch.exp(x)\n",
    "torch.log(x.abs() + 1e-10)\n",
    "torch.sin(x)\n",
    "torch.cos(x)\n",
    "torch.sigmoid(x)\n",
    "torch.tanh(x)\n",
    "torch.clamp(x, min=0, max=1)\n",
    "torch.clip(x, 0, 1)\n",
    "torch.round(x)\n",
    "torch.floor(x)\n",
    "torch.ceil(x)\n",
    "\n",
    "x.prod()\n",
    "x.sum()\n",
    "x\n",
    "x.sum(dim=1)\n",
    "x.sum(dim=1, keepdim=True)\n",
    "print(x)\n",
    "x.max(dim=1)\n",
    "x.cumsum(dim=1)\n",
    "x.cumsum(dim=2)\n",
    "x.argmax(dim=1)\n",
    "torch.median(x)\n",
    "torch.topk(x, 3, dim=1)\n",
    "torch.sort(x, dim=1)\n",
    "torch.where(x > 0, 999, torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8da4fd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# core properties\n",
    "x = torch.randn(2, 3, 4)\n",
    "x.shape\n",
    "x.dim()\n",
    "x.numel()\n",
    "x.dtype\n",
    "x.device\n",
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56523ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8046,  0.9434, -0.9488,  0.3731],\n",
      "         [ 0.4768, -0.2819,  1.1088, -0.2260],\n",
      "         [-0.0728,  2.1800,  0.1333,  0.5033]],\n",
      "\n",
      "        [[ 0.6066,  0.5870, -1.1039,  0.8438],\n",
      "         [-0.8987,  0.3118,  0.8699, -0.2911],\n",
      "         [-0.8762, -0.0764,  1.1834,  0.1131]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8046,  0.9434, -0.9488,  0.3731],\n",
       "         [ 0.4768, -0.2819,  1.1088, -0.2260],\n",
       "         [-0.0728,  2.1800,  0.1333,  0.5033],\n",
       "         [ 0.8046,  0.9434, -0.9488,  0.3731],\n",
       "         [ 0.4768, -0.2819,  1.1088, -0.2260],\n",
       "         [-0.0728,  2.1800,  0.1333,  0.5033],\n",
       "         [ 0.8046,  0.9434, -0.9488,  0.3731],\n",
       "         [ 0.4768, -0.2819,  1.1088, -0.2260],\n",
       "         [-0.0728,  2.1800,  0.1333,  0.5033]],\n",
       "\n",
       "        [[ 0.6066,  0.5870, -1.1039,  0.8438],\n",
       "         [-0.8987,  0.3118,  0.8699, -0.2911],\n",
       "         [-0.8762, -0.0764,  1.1834,  0.1131],\n",
       "         [ 0.6066,  0.5870, -1.1039,  0.8438],\n",
       "         [-0.8987,  0.3118,  0.8699, -0.2911],\n",
       "         [-0.8762, -0.0764,  1.1834,  0.1131],\n",
       "         [ 0.6066,  0.5870, -1.1039,  0.8438],\n",
       "         [-0.8987,  0.3118,  0.8699, -0.2911],\n",
       "         [-0.8762, -0.0764,  1.1834,  0.1131]],\n",
       "\n",
       "        [[ 0.8046,  0.9434, -0.9488,  0.3731],\n",
       "         [ 0.4768, -0.2819,  1.1088, -0.2260],\n",
       "         [-0.0728,  2.1800,  0.1333,  0.5033],\n",
       "         [ 0.8046,  0.9434, -0.9488,  0.3731],\n",
       "         [ 0.4768, -0.2819,  1.1088, -0.2260],\n",
       "         [-0.0728,  2.1800,  0.1333,  0.5033],\n",
       "         [ 0.8046,  0.9434, -0.9488,  0.3731],\n",
       "         [ 0.4768, -0.2819,  1.1088, -0.2260],\n",
       "         [-0.0728,  2.1800,  0.1333,  0.5033]],\n",
       "\n",
       "        [[ 0.6066,  0.5870, -1.1039,  0.8438],\n",
       "         [-0.8987,  0.3118,  0.8699, -0.2911],\n",
       "         [-0.8762, -0.0764,  1.1834,  0.1131],\n",
       "         [ 0.6066,  0.5870, -1.1039,  0.8438],\n",
       "         [-0.8987,  0.3118,  0.8699, -0.2911],\n",
       "         [-0.8762, -0.0764,  1.1834,  0.1131],\n",
       "         [ 0.6066,  0.5870, -1.1039,  0.8438],\n",
       "         [-0.8987,  0.3118,  0.8699, -0.2911],\n",
       "         [-0.8762, -0.0764,  1.1834,  0.1131]]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape\n",
    "x = torch.randn(2, 3, 4)\n",
    "x.view(2, 12)\n",
    "x.reshape(2, 12)\n",
    "x.view(-1)\n",
    "x.flatten()\n",
    "x.flatten(1)\n",
    "\n",
    "# add dim\n",
    "x.unsqueeze(0)\n",
    "x.unsqueeze(-1)\n",
    "m = x.transpose(0, 1).contiguous()\n",
    "n = x.transpose(0, 1)\n",
    "x.transpose(0, 1)\n",
    "x.permute(2, 0, 1)\n",
    "\n",
    "print(x)\n",
    "\n",
    "torch.cat([x, x], dim=0)\n",
    "torch.stack([x, x], dim=0)\n",
    "torch.split(x, 2, dim=2)\n",
    "torch.chunk(x, 2, dim=2)\n",
    "\n",
    "torch.repeat_interleave(x, 3, dim=0)\n",
    "x.expand(2, 3, 4)\n",
    "x.repeat(2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9d5a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7402,  1.9651, -1.5312, -0.7930,  0.9341],\n",
       "         [-0.5728,  0.2285,  0.3958, -0.0130, -0.8526],\n",
       "         [-0.3905,  0.8087, -1.2173, -0.6669,  0.2288],\n",
       "         [ 0.0664, -0.7387,  0.1284, -0.5602, -0.2608]],\n",
       "\n",
       "        [[ 0.7837,  0.1825,  0.1997,  0.6498,  1.7486],\n",
       "         [-0.4840, -0.1382,  0.9988, -0.3013,  1.1092],\n",
       "         [-1.2053, -1.3156, -0.6011,  0.0480, -1.6663],\n",
       "         [-0.0547, -0.7900, -0.5167,  1.6236,  0.9342]],\n",
       "\n",
       "        [[-2.1420,  0.4545, -0.2534,  0.2482, -0.4428],\n",
       "         [-0.2880, -0.5616, -0.8953,  0.5639, -0.3590],\n",
       "         [ 0.3355, -0.8704, -1.0210, -2.1102, -0.1744],\n",
       "         [ 0.2264, -0.6930, -0.4195, -0.0839, -0.5192]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform\n",
    "x = torch.randn(3, 4, 5)\n",
    "x.int()\n",
    "x.long()\n",
    "x.float()\n",
    "x.double()\n",
    "x.half()\n",
    "x.bool()\n",
    "x.to(torch.int32)\n",
    "\n",
    "# device\n",
    "# x.cuda()\n",
    "# x.to('cuda:0)\n",
    "x.cpu()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec90675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0652, -0.2533,  0.9170, -0.7959, -0.5045,  0.1685],\n",
      "         [ 1.8945,  0.4327, -2.5662, -0.5106,  1.6490, -1.1339],\n",
      "         [-0.2611, -0.9185, -1.5674,  1.3769,  0.5577,  0.2158],\n",
      "         [-0.3005,  0.6127, -0.1388,  0.2547,  1.2757,  0.3722],\n",
      "         [ 1.4643, -0.9996,  0.8162,  0.4761,  0.1240, -0.2115]],\n",
      "\n",
      "        [[ 0.4498, -0.3081, -0.1387,  0.6527,  1.8462,  0.8729],\n",
      "         [ 0.1772, -0.4845, -1.1760, -1.0828, -0.1822,  0.3550],\n",
      "         [ 1.0757,  0.5844,  0.3320,  0.7014, -1.5299,  1.0265],\n",
      "         [ 0.1302, -0.3371, -0.3607,  1.2070, -0.2084, -0.3488],\n",
      "         [ 0.5626, -0.2643, -0.2643, -0.4714,  0.1122,  0.2665]],\n",
      "\n",
      "        [[-0.1850, -0.5589, -1.4095,  0.2071,  0.4605,  0.8251],\n",
      "         [ 0.1699,  0.1108, -0.3817, -0.2245, -0.3563,  0.5686],\n",
      "         [-1.4455,  1.4435, -0.5477, -0.8545, -1.0943, -1.1530],\n",
      "         [ 1.4274, -2.0076,  1.5345, -2.2431, -1.6794,  1.3923],\n",
      "         [-1.0439,  1.4954, -0.0311,  0.5872, -0.1888, -0.6585]],\n",
      "\n",
      "        [[-0.2598, -0.8073, -0.9033, -0.3181, -0.0726,  0.5204],\n",
      "         [ 1.4770,  1.1013,  1.1955,  0.1970, -0.8100,  2.3893],\n",
      "         [-0.7065, -0.3777, -2.2604, -0.4807, -0.6374,  0.2135],\n",
      "         [ 0.2269, -0.5287, -0.0955, -0.8007, -0.5977, -0.8886],\n",
      "         [-0.4006, -0.0543,  0.5745, -0.8355,  0.1199,  0.4793]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0652,  1.8945, -0.2611, -0.3005,  1.4643],\n",
       "        [ 0.4498,  0.1772,  1.0757,  0.1302,  0.5626],\n",
       "        [-0.1850,  0.1699, -1.4455,  1.4274, -1.0439],\n",
       "        [-0.2598,  1.4770, -0.7065,  0.2269, -0.4006]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 索引 indexing\n",
    "# 切片 slicing\n",
    "x = torch.randn(4, 5, 6)\n",
    "print(x)\n",
    "x[0]\n",
    "x[:2]\n",
    "x[1, :, 3]\n",
    "x[..., 0]\n",
    "x[:, 0, :]\n",
    "x[0, :, :]\n",
    "x[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758ab4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (linear): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network\n",
    "from torch import nn\n",
    "\n",
    "nn.Linear(10, 10)\n",
    "nn.Conv1d(16, 32, 3, 1, 1)\n",
    "nn.Conv2d(16, 32, 3, 1, 1)\n",
    "nn.Conv3d(16, 32, 3, 1, 1)\n",
    "\n",
    "nn.MaxPool2d(2, 2)\n",
    "nn.AvgPool2d(2, 2)\n",
    "nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "# Normalization\n",
    "nn.BatchNorm1d(20)\n",
    "nn.BatchNorm2d(20)\n",
    "nn.LayerNorm(20)\n",
    "nn.GroupNorm(8, 64)\n",
    "nn.InstanceNorm2d(64)\n",
    "\n",
    "nn.Embedding(1000, 128)\n",
    "nn.LSTM(10, 20, 2)\n",
    "\n",
    "nn.TransformerEncoderLayer(128, 4, 128)\n",
    "nn.MultiheadAttention(128, 4)\n",
    "\n",
    "nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1)\n",
    ")\n",
    "\n",
    "nn.ModuleList([nn.Linear(10, 10) for _ in range(5)])\n",
    "nn.ModuleDict({'linear': nn.Linear(10, 10), 'relu': nn.ReLU()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "050e8a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CosineEmbeddingLoss()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "loss = nn.MSELoss()\n",
    "nn.BCELoss()\n",
    "nn.CrossEntropyLoss()\n",
    "nn.NLLLoss()\n",
    "nn.PoissonNLLLoss()\n",
    "nn.GaussianNLLLoss()\n",
    "nn.KLDivLoss()\n",
    "nn.CosineEmbeddingLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "414f60fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adagrad (\n",
       "Parameter Group 0\n",
       "    differentiable: False\n",
       "    eps: 1e-10\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    initial_accumulator_value: 0\n",
       "    lr: 0.001\n",
       "    lr_decay: 0\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer\n",
    "model = nn.Linear(10, 1)\n",
    "\n",
    "import torch.optim as optim\n",
    "optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "optim.RMSprop(model.parameters(), lr=0.001)\n",
    "optim.Adagrad(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21665bb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MSELoss' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m):\n\u001b[32m      5\u001b[39m     optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m()\n\u001b[32m      7\u001b[39m     optimizer.step()\n\u001b[32m      8\u001b[39m     scheduler.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_tool/lib/python3.12/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MSELoss' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "# lr\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622c827",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected !nested_tensorlist[0].empty() to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 梯度裁剪\u001b[39;00m\n\u001b[32m     21\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_value_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_tool/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_tool/lib/python3.12/site-packages/torch/nn/utils/clip_grad.py:283\u001b[39m, in \u001b[36mclip_grad_value_\u001b[39m\u001b[34m(parameters, clip_value, foreach)\u001b[39m\n\u001b[32m    280\u001b[39m clip_value = \u001b[38;5;28mfloat\u001b[39m(clip_value)\n\u001b[32m    282\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m grouped_grads = \u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([grads], _) \u001b[38;5;129;01min\u001b[39;00m grouped_grads.items():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    287\u001b[39m         foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    288\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(cast(\u001b[38;5;28mlist\u001b[39m[Tensor], grads), device=device)\n\u001b[32m    289\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m (foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_tool/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/llm_tool/lib/python3.12/site-packages/torch/utils/_foreach_utils.py:48\u001b[39m, in \u001b[36m_group_tensors_by_device_and_dtype\u001b[39m\u001b[34m(tensorlistlist, with_indices)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;129m@no_grad\u001b[39m()\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_group_tensors_by_device_and_dtype\u001b[39m(\n\u001b[32m     45\u001b[39m     tensorlistlist: TensorListList,\n\u001b[32m     46\u001b[39m     with_indices: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     47\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[torch.device, torch.dtype], \u001b[38;5;28mtuple\u001b[39m[TensorListList, Indices]]:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected !nested_tensorlist[0].empty() to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "# 开启梯度\n",
    "x = torch.randn(2, 3, requires_grad=True)\n",
    "y = x ** 2\n",
    "z = y.mean()\n",
    "z.backward()  # 反向传播\n",
    "x.grad  # 查看梯度\n",
    "\n",
    "x.grad.zero_()\n",
    "# torch.autograd.grad(z, x)\n",
    "\n",
    "with torch.no_grad():  # 禁用梯度计算\n",
    "    y = x * 2\n",
    "\n",
    "with torch.set_grad_enabled(False):  # 禁用梯度计算\n",
    "    y = x * 2\n",
    "\n",
    "x.detach()\n",
    "x.requires_grad_(False)\n",
    "\n",
    "# 梯度裁剪\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63e43839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1379,  0.6082,  0.6019,  0.0910,  0.4903],\n",
       "        [ 0.1235,  0.7619, -0.3717, -0.0589, -0.5125],\n",
       "        [ 0.3117,  0.0330, -0.5837,  0.5738,  0.4815]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init\n",
    "w = torch.empty(3, 5)\n",
    "nn.init.uniform_(w, a=0, b=1)\n",
    "nn.init.normal_(w, mean=0, std=1)\n",
    "nn.init.constant_(w, 0.5)\n",
    "nn.init.xavier_uniform_(w)  # Xavier 初始化\n",
    "nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')  # He 初始化\n",
    "nn.init.orthogonal_(w)  # 正交初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ea4fb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5763,  0.2137, -0.0408, -0.9574, -1.9224],\n",
      "         [ 0.0907, -0.5304, -0.1101, -1.0877, -1.7759],\n",
      "         [-0.1896, -2.2964, -2.0669,  0.3943, -1.8009],\n",
      "         [ 1.6133, -0.5444, -0.1867,  0.3827, -1.2904]],\n",
      "\n",
      "        [[-1.3610, -0.2035, -0.4029, -3.5387, -0.9285],\n",
      "         [ 0.3060, -0.9476, -0.4722, -3.6690, -0.7820],\n",
      "         [ 0.0257, -2.7137, -2.4290, -2.1870, -0.8070],\n",
      "         [ 1.8286, -0.9617, -0.5488, -2.1986, -0.2965]],\n",
      "\n",
      "        [[ 0.7474,  0.5435,  0.1603, -1.0483, -2.0233],\n",
      "         [ 2.4143, -0.2006,  0.0911, -1.1786, -1.8769],\n",
      "         [ 2.1340, -1.9666, -1.8658,  0.3034, -1.9018],\n",
      "         [ 3.9369, -0.2146,  0.0144,  0.2919, -1.3913]]])\n"
     ]
    }
   ],
   "source": [
    "# 广播规则：从右往左比较维度，维度相等或其中一个为1则可以广播\n",
    "x = torch.randn(3, 1, 5)\n",
    "y = torch.randn(1, 4, 5)\n",
    "z = x + y  # 结果: [3, 4, 5]\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9c785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
