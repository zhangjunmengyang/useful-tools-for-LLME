{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c46ecf1-6011-4d9b-8cc7-6a211c8a3a85",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "\n",
    "LLM 具有解决通用任务的能力，其性能测评涵盖广泛如 NLP、知识、数学、代码、写作、长上下文能力和推理等任务。\n",
    "\n",
    "需要区分任务和能力：\n",
    "\n",
    "1. 任务：具体需要解决的场景，如文本分类\n",
    "2. 能力：更加抽象的模型内在特性。如上下文理解、推理能力\n",
    "\n",
    "能力的提升，会带来特定任务性能的表现。 对于 NLP 模型到 LLM 的能力测评差异，语言模型从具体任务测评 发展到 **通用** 能力测评。\n",
    "\n",
    "能力是通过任务测评来给予一种客观的度量，如测试模型的数学推理能力， 则会使用一些奥数竞赛题作为测评。\n",
    "\n",
    "这种客观度量模型能力的方式称为 “基准（benchmark）测试”。\n",
    "\n",
    "在 GPT-3 预训练模型中，通过 few-shot prompting 在多任务上测评，发现语言模型的涌现能力。对于分类任务：\n",
    "\n",
    "- {example问题1}{example答案1}{问题输入}，回答：\n",
    "\n",
    "这种方式让模型 generation 出回答，再对回答进行匹配。翻译任务需要判别预测序列与标签结果，这种类型的测评方案其答案主观，benchmark 一般会把主观问题转化成客观检验形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f88d5d-a379-416c-a40f-f36deb07fa01",
   "metadata": {},
   "source": [
    "## MMLU 知识测评\n",
    "\n",
    "MMLU 是多个学科的选择题数据集，选择题形式便于检验答案，测评结果体现模型的“知识”能力。\n",
    "\n",
    "[例如](https://huggingface.co/datasets/cais/mmlu/viewer/abstract_algebra/test?row=0) ：\n",
    "\n",
    "\n",
    "\n",
    "| question     | Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. |\n",
    "| ------------ | ------------------------------------------------------------ |\n",
    "| choices      | [ \"0\", \"4\", \"2\", \"6\" ]                                       |\n",
    "| answer       | B                                                            |\n",
    "| **question** | **Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of `<p>` in S_5.** |\n",
    "| choices      | ['8', '2', '24', '120']                                      |\n",
    "| answer       | C                                                            |\n",
    "\n",
    "\n",
    "\n",
    "对于 abstract algebra 学科，可以结构化来组织完整测评数据集。\n",
    "\n",
    "LLM 如何测评？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48f6511-c3dc-4a76-851e-fcd41f61f48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1217bcd70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c9cac-0e0f-42c2-8f50-dc6cea6be8f7",
   "metadata": {},
   "source": [
    "## Format\n",
    "\n",
    "增加例子, 将目标问题序列化成开口问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29375b53-604e-4512-adb3-764ce31ae85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict choice <example>Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:B<\\example><question>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.<\\question><choices> (A)8 (B)2 (C)24 (D)120<\\choices>answer:\n"
     ]
    }
   ],
   "source": [
    "def template_mmlu( example, question, choices):\n",
    "    task_example = 'Predict choice <example>' + example + '<\\example>' \n",
    "    input_question = '<question>' + question + '<\\question>'\n",
    "    input_choices = '<choices> (A)' + choices[0] + ' (B)' + choices[1] + ' (C)' + choices[2]+ ' (D)' + choices[3] + '<\\choices>'\n",
    "    return task_example + input_question + input_choices + 'answer:' \n",
    "\n",
    "example = 'Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:B'\n",
    "\n",
    "question = 'Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.'\n",
    "choices = ['8', '2', '24', '120']\n",
    "\n",
    "prompt = template_mmlu(example, question, choices)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324996e4-a676-4595-9e23-5a0704b3797d",
   "metadata": {},
   "source": [
    "## dummy tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00796571-8933-454e-b953-fbe9d9da97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "class SimplestTokenizer:\n",
    "    def __init__(self, text):\n",
    "        tokens = list(text)\n",
    "        self.vocab = {}\n",
    "        self.vocab_reverse = {}\n",
    "        idx = 0\n",
    "        for i in tokens:\n",
    "            if i not in self.vocab:\n",
    "                self.vocab[i] = idx\n",
    "                self.vocab_reverse[idx] = i\n",
    "                idx += 1\n",
    "    def encode(self, text, return_pt = False):\n",
    "        tokens = list(text)\n",
    "        token_ids = [ self.vocab[token] for token in tokens]\n",
    "        if return_pt:\n",
    "            token_ids = torch.tensor(token_ids, dtype = torch.long).unsqueeze(0)\n",
    "        return token_ids\n",
    "    def decode(self, ids):\n",
    "        token_list = [self.vocab_reverse[idx] for idx in ids]\n",
    "        text = ''.join(token_list)\n",
    "        return text\n",
    "\n",
    "tokenizer = SimplestTokenizer(prompt)\n",
    "input_ids = tokenizer.encode(prompt, return_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77486f84-90bd-45d1-a4de-680efdc7c268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1993, -0.4260,  0.3250,  ..., -0.6383, -0.2980,  0.2777],\n",
       "         [-0.2143,  0.1726,  0.0864,  ..., -0.4307,  0.1291,  0.6233],\n",
       "         [ 0.2139, -0.4257,  0.8965,  ...,  0.3269, -0.4121,  0.3931],\n",
       "         ...,\n",
       "         [ 0.2139, -0.4257,  0.8965,  ...,  0.3269, -0.4121,  0.3931],\n",
       "         [-0.2143,  0.1726,  0.0864,  ..., -0.4307,  0.1291,  0.6233],\n",
       "         [ 0.1097,  0.5253, -0.1027,  ..., -0.0012,  0.0870,  0.5525]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLLM(nn.Module):\n",
    "    def __init__(self, vocab_size = 100):\n",
    "        super().__init__()\n",
    "        self.dim = 32\n",
    "        self.embd = nn.Embedding(vocab_size, self.dim)\n",
    "        self.w0 = nn.Linear(self.dim, self.dim)\n",
    "        self.w1 = nn.Linear(self.dim, self.dim)\n",
    "        self.lm_head = nn.Linear(self.dim, vocab_size)\n",
    "    def forward(self, x):\n",
    "        e = self.embd(x)\n",
    "        e = torch.sin(self.w0(e).mean(dim = 1, keepdim=True)) + self.w1(e)\n",
    "        logits = self.lm_head(e)\n",
    "        return logits\n",
    "        \n",
    "vocab_size = len(tokenizer.vocab)\n",
    "model = MyLLM(vocab_size = vocab_size)\n",
    "model(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797f5cd-2509-4e05-aee1-baadaf494ed7",
   "metadata": {},
   "source": [
    "## 生成式测评\n",
    "\n",
    "生成一个token作为选项，生成时可能产生非选项 ABCD 的答案\n",
    "\n",
    "1. 直接判别生成 token id 与 label id 是否一致， 若不一致则为预测错误\n",
    "2. 基于预测分布的 ABCD token 概率\n",
    "\n",
    "### 直接判别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4837a3-d725-4403-9611-e2b0b2657d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict argmax next-token id: tensor([3])\n",
      "predict answer: d\n",
      "next-token prediction logits shape torch.Size([1, 49])\n",
      "tokenizer vocab_size: 49\n",
      "label token id: [37]\n",
      "prediction correctness: False\n"
     ]
    }
   ],
   "source": [
    "def generate(model, x, max_new_tokens = 20):\n",
    "    for i in range(max_new_tokens):\n",
    "        logits = model(x)[:, -1, :]\n",
    "        new_token = torch.argmax(logits, dim = -1)\n",
    "        x = torch.cat((x, new_token.unsqueeze(1)), dim = 1)\n",
    "    return x, new_token, logits\n",
    "\n",
    "_, new_token, logits = generate(model, input_ids, max_new_tokens=1) #只预测一个 token\n",
    "print('predict argmax next-token id:',new_token)\n",
    "print('predict answer:',tokenizer.decode(new_token.tolist()))\n",
    "print('next-token prediction logits shape', logits.shape)\n",
    "print('tokenizer vocab_size:', len(tokenizer.vocab))\n",
    "\n",
    "label_id = tokenizer.encode(text = 'C')\n",
    "print('label token id:', label_id)\n",
    "print('prediction correctness:',new_token.tolist()[0] == label_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a3b0b-e5e1-4bc1-b4aa-374193358bfb",
   "metadata": {},
   "source": [
    "### 概率判别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45365dce-059c-4e88-a1f3-0046752e69ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 35 37 38\n",
      "0.02757927030324936\n",
      "0.010749058797955513\n",
      "0.020917844027280807\n",
      "0.03135909140110016\n"
     ]
    }
   ],
   "source": [
    "token_id_a = tokenizer.encode(text = 'A')[0]\n",
    "token_id_b = tokenizer.encode(text = 'B')[0]\n",
    "token_id_c = tokenizer.encode(text = 'C')[0]\n",
    "token_id_d = tokenizer.encode(text = 'D')[0]\n",
    "\n",
    "print(token_id_a, token_id_b, token_id_c, token_id_d)\n",
    "\n",
    "p = F.softmax(logits[0, :], dim = 0)\n",
    "print(p[token_id_a].item())\n",
    "print(p[token_id_b].item())\n",
    "print(p[token_id_c].item())\n",
    "print(p[token_id_d].item())\n",
    "\n",
    "# 答案为概率最大的 D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd73d1d-6f19-4557-b2eb-27cf855b67dd",
   "metadata": {},
   "source": [
    "## PPL 判别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcc3284-3e7c-41cd-a224-f7c6ecd5469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict choice <example>Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:B<\\example><question>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.<\\question><choices> (A)8 (B)2 (C)24 (D)120<\\choices>answer:C\n"
     ]
    }
   ],
   "source": [
    "prompt_a = prompt + 'A'\n",
    "prompt_b = prompt + 'B'\n",
    "prompt_c = prompt + 'C'\n",
    "prompt_d = prompt + 'D'\n",
    "\n",
    "print(prompt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96731e49-058a-4811-82e8-5a4ea4951a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0448, -0.0402, -0.3794],\n",
      "        [ 0.9052,  0.3824,  1.4473]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3794],\n",
       "        [ 0.3824]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.tensor([[2],[1]], dtype = torch.long)\n",
    "print(a)\n",
    "a.gather(index = b, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed643465-6b2b-459f-8a79-b904f1f10d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 292])\n",
      "torch.Size([1, 292, 49])\n",
      "torch.Size([291, 1])\n",
      "tensor(3.7690, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(prompt_c, return_pt=True)\n",
    "# print(input_ids)\n",
    "_, seq_len = input_ids.shape\n",
    "      \n",
    "logits = model(input_ids)\n",
    "print(input_ids.shape)\n",
    "print(logits.shape)\n",
    "\n",
    "p = F.softmax(logits, dim = -1)\n",
    "p_next_token = p[0,:-1,:].gather(index = input_ids[0, 1:, None], dim = 0)\n",
    "print(p_next_token.shape)\n",
    "\n",
    "PPL = -p_next_token.log().mean()\n",
    "print(PPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95912af-b812-473a-870a-2336d72a1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.768345832824707\n",
      "3.767855405807495\n",
      "3.769028663635254\n",
      "3.767888069152832\n"
     ]
    }
   ],
   "source": [
    "def mmlu_ppl(prompt, tokenizer, model):\n",
    "    input_ids = tokenizer.encode(prompt, return_pt=True)\n",
    "    logits = model(input_ids)\n",
    "    p = F.softmax(logits, dim = -1)\n",
    "    p_next_token = p[0,:-1,:].gather(index = input_ids[0, 1:, None], dim = 0)\n",
    "    PPL = -p_next_token.log().mean()\n",
    "    return PPL.item()\n",
    "\n",
    "print(mmlu_ppl(prompt_a, tokenizer, model))\n",
    "print(mmlu_ppl(prompt_b, tokenizer, model))\n",
    "print(mmlu_ppl(prompt_c, tokenizer, model))\n",
    "print(mmlu_ppl(prompt_d, tokenizer, model))\n",
    "\n",
    "# 最小PPL为答案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b4a4e-9569-4509-a4e5-a2ff6fe462af",
   "metadata": {},
   "source": [
    "## PPL 答案\n",
    "\n",
    "对与选项 PPL，本身model有预测偏置。 以选项内容作为答案，再计算 PPL， 能够减少预测偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c7f939b-610b-4ac2-b3fc-6bd4c1acbf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Predict choice <example>Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:4<\\\\example><question>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.<\\\\question><choices> (A)8 (B)2 (C)24 (D)120<\\\\choices>answer:8', 'Predict choice <example>Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:4<\\\\example><question>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.<\\\\question><choices> (A)8 (B)2 (C)24 (D)120<\\\\choices>answer:2', 'Predict choice <example>Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:4<\\\\example><question>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.<\\\\question><choices> (A)8 (B)2 (C)24 (D)120<\\\\choices>answer:24', 'Predict choice <example>Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:4<\\\\example><question>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.<\\\\question><choices> (A)8 (B)2 (C)24 (D)120<\\\\choices>answer:120']\n"
     ]
    }
   ],
   "source": [
    "# example 的答案 (B)-> 4\n",
    "example = 'Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q. <choices> (A)0 (B)4 (C)2 (D)6 answer:4'\n",
    "\n",
    "question = 'Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.'\n",
    "choices = ['8', '2', '24', '120']\n",
    "\n",
    "prompt = template_mmlu(example, question, choices)\n",
    "# print(prompt)\n",
    "\n",
    "prompt_list = []\n",
    "for choice in choices:\n",
    "    prompt_list.append( prompt + choice )\n",
    "print(prompt_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78310e19-1170-4017-beb0-87b6d4df0a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.770315647125244, 3.7718098163604736, 3.774035692214966, 3.7709386348724365]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "result = [ mmlu_ppl(prompt, tokenizer, model) for prompt in prompt_list ]\n",
    "print(result)\n",
    "idx = torch.argmin(torch.tensor(result)).item()\n",
    "print(idx) # 0:A, 1:B, 2:C, 3:D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09ded6-f4b9-4a21-bc61-f3b1c0faf9be",
   "metadata": {},
   "source": [
    "## 指标描述\n",
    "\n",
    "- pass@N 指回答采样（N>1时，需要sample，非greedy search生成）数量 N 次，至少有一次答对了。比如让模型写代码，写了100次，至少有一次通过了，也算成功。\n",
    "- cot@N 给定的示例有 N 个， 即 few-shot learning 中 exmaple的数量\n",
    "- Magority@N 投票，采样的 4 个答案中（A,B,A,C），有2个为 A即是最高出现频次，则答案为 A。投票结果也可结合概率计算（A:0.4,B:0.55,A:0.6,C:0.3）,此时 A平均为0.5，小于B。\n",
    "\n",
    "最严格的是 zero-shot greedy-search 结果给出 pass@1, cot@1。 但语言模型是随机模型，因此采样 / few-shot leanring，仍然能体现出其\"预测分布\"的准确性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9205f9-7263-47a9-b063-523280bab416",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "1. benchmark 的数据集设置中，其答案是容易被 check 的。 对于主观类问题，如果能转化为 客观类 问题形式，则容易进行测评\n",
    "2. 本文给出 gen选项、PPL选项、PPL答案三种方式，更难的方式是 gen 答案。\n",
    "3. 对比模型性能时需要看清测评的条件：采样数量、cot数量、...\n",
    "4. 另外常用的典型测评方式为：LLM-As-a-judge、数学答案规则判别、人工判别\n",
    "5. pretrained模型其生成内容不稳定，但通常来说 pretrained 模型有较完整的知识分布，性能保留最好。 而微调操作，则“强化”一部分能力，必然产生“遗忘现象”（遗忘程度不一）导致其他能力下降（跷跷板现象）\n",
    "6. pretrained内部能力全面但不显化（如你掌握动态规划编程技巧，但是面试时无法回答hard 难度代码），而各种微调、ICL技术，则能显化/引出模型的推导结果（ICL如面试官给你提示如迭代方程，你根据提示能编写完整代码）\n",
    "7. 微调后的模型一般采用生成式的判别"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
