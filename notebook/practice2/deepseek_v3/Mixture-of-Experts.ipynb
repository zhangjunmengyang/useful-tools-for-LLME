{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8b27ee-a58b-4fc2-be55-b334ed0613f6",
   "metadata": {},
   "source": [
    "# MoE\n",
    "\n",
    "混合专家(Mixture of Experts, MoE) 是一种集成学习方法，将输入数据分配给特定专家处理，从而提高特征学习的效率。MoE包含：\n",
    "\n",
    "1. 门控（Gated）：输入数据，门控网络输出分配的专家权重。\n",
    "2. 专家（Experts）：各专家处理数据。在神经网络中，专家可以是特征学习器 FFN/MLP/Linear，专家组指多个特征学习器。在 Transformer 类模型，通常由多个 FFN 与 1个门控网络构成。\n",
    "3. 混合（Mixture）：将各专家输出加权组合，得到 MoE 输出\n",
    "\n",
    "本 notebook 讨论 MoE、SMoE、balance loss，另外引入问题\n",
    "\n",
    "- FFN 对 Transformer 网络学习的重要性，为何要在 FFN 中想办法扩展参数量（模型容量），而不在 Attention 扩展？\n",
    "- MoE 的学习的本质是什么？是否符合直觉，专家能够处理特定领域特征\n",
    "- 门控对象是 token-level 还是 sentence-level 的？\n",
    "- 引入 MoE 是否显著增加计算量？是否各专家输出特征会用冗余？\n",
    "- 稀疏门控是否导致 MoE 特征不稳定？\n",
    "- 稀疏门控可导吗？不可导的情况下如何训练？\n",
    "- 稀疏 MoE 训练难点是什么？有哪些策略缓解？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854cd5b-3bc3-40fa-b8d0-ff5438fa6e06",
   "metadata": {},
   "source": [
    "## 关键 MoE 工作\n",
    "\n",
    "1. MoE，1991: Adaptive mixtures of local experts\n",
    "2. SMoE，2017: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\n",
    "3. EP，2021: GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding\n",
    "4. Loss，2022: Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,\n",
    "5. MoE-LLM，2023.12: Mixtral of Experts\n",
    "6. DeepSeek-V1，2024.01 \n",
    "8. DeepSeek-V2，2024.05\n",
    "9. DeepSeek-V3，2024.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83c390-72a8-47dd-9ab0-b1a8a4d7c625",
   "metadata": {},
   "source": [
    "## MoE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc542fd1-7873-495e-ac53-a8fa1ac1fbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10bc0d070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23205e6-fc09-474c-a497-e69d4df2f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoEBasic(\n",
      "  (experts): ModuleList(\n",
      "    (0-7): 8 x Expert(\n",
      "      (w): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gate): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, dim=512):\n",
    "        '''\n",
    "        在 LLM 中, FFN 功能层作为 Expert\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.w = nn.Linear(self.dim, self.dim)\n",
    "    def forward(self, x):\n",
    "        return self.w(x)\n",
    "\n",
    "class MoEBasic(nn.Module):\n",
    "    def __init__(self, dim=512, num_experts=8):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_experts = num_experts\n",
    "        self.experts = nn.ModuleList(\n",
    "            [ Expert(dim = self.dim) for _ in range(self.num_experts) ]\n",
    "        )\n",
    "        self.gate = nn.Linear(self.dim, self.num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: bsz, seq_len, dim\n",
    "        '''\n",
    "        weight = self.gate(x)\n",
    "        weight = F.softmax(weight, dim = -1) # bsz, seq_len, num_experts\n",
    "\n",
    "        output = torch.zeros_like(x)\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            output += weight[...,i].unsqueeze(-1) * expert(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "dim = 512\n",
    "num_experts = 8\n",
    "moe = MoEBasic(dim=dim,  num_experts=num_experts)\n",
    "print(moe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65948be8-446e-4ace-9467-e7696e9a361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "bsz = 2\n",
    "seq_len = 3\n",
    "\n",
    "X = torch.randn(bsz, seq_len, dim)\n",
    "Y = moe(X)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b6ccf0-d84b-4de8-962e-ae309f55bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4706],\n",
      "         [-0.2382]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4706,  0.4706,  0.4706],\n",
       "         [-0.2382, -0.2382, -0.2382]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dim broadcast\n",
    "x = torch.ones(1,2,3)\n",
    "weight = torch.randn(1,2,1) \n",
    "print(weight)\n",
    "x*weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7abd0a3-13aa-4201-ae7c-79c9a8d07187",
   "metadata": {},
   "source": [
    "上述的 MoE 是最基础的版本，各专家协作进行特征表示。 有 “专家竞争的loss” 版本。\n",
    "\n",
    "后续的改进均以专家合作为主（加权特征），给定专家数量为N\n",
    "\n",
    "- MoE: 筛选 top-N 专家\n",
    "- sMoE：筛选 top-k 专家, $k\\in[1,N]$ \n",
    "- Switch-Transformer：筛选 top-1 专家\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c0ad9-93b8-48d7-8a21-48a329772fe1",
   "metadata": {},
   "source": [
    "## SMoE\n",
    "\n",
    "选择 top-k 权重专家, 对于非top-k专家的 logits 设置为 $-\\infty$, 如下：\n",
    "\n",
    "\n",
    "$$\n",
    "G(x) = \\texttt{Softmax}(\\texttt{KeepTopK}(H(x), k))\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\texttt{KeepTopK}(v, k)_i = \\begin{cases}\n",
    "            v_i & \\text{if $v_i$ is in the top $k$ elements of $v$.} \\\\\n",
    "            -\\infty & \\text{otherwise.}\n",
    "        \\end{cases}\n",
    "$$\n",
    "\n",
    "本 notebook 实现方法为， \n",
    "\n",
    "1. logist 直接算 softmax： p1,p2,...,p8\n",
    "2. 选出概率top-2 专家，如 p2, p8\n",
    "3. 将两者做归一化 p2 / (p2+p8), p8/(p2+p8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd8442b-1a91-4e1e-b72d-a0420321530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7493, -1.3844, -2.1473,  0.1755,  0.7047],\n",
      "        [ 0.9629, -0.1419, -0.5430,  0.2240, -0.2433],\n",
      "        [ 1.9174,  0.9862,  1.0908, -1.2830,  0.0711]])\n",
      "tensor([[0.7493, 0.7047],\n",
      "        [0.9629, 0.2240],\n",
      "        [1.9174, 1.0908]]) tensor([[0, 4],\n",
      "        [0, 3],\n",
      "        [0, 2]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn(3,5)\n",
    "print(data)\n",
    "v, idx = torch.topk(data, k=2, dim = -1)\n",
    "print(v, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e551063c-cb4f-4334-9c2b-6c40a0daf17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoESparse(\n",
      "  (experts): ModuleList(\n",
      "    (0-7): 8 x Expert(\n",
      "      (w): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gate): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MoESparse(MoEBasic):\n",
    "    def __init__(self, dim=512, num_experts=8, topk = 2):\n",
    "        super().__init__()\n",
    "        self.topk = 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, _ = x.shape\n",
    "        weight = self.gate(x)\n",
    "        weight = F.softmax(weight, dim = -1) # bsz, seq_len, num_experts\n",
    "\n",
    "        # process top-k index\n",
    "        v, idx = torch.topk(weight, dim = -1, k=self.topk)\n",
    "        print('token选择的专家 id 是不同的:', idx)\n",
    "        \n",
    "        weight_sparse = torch.zeros_like(weight)\n",
    "        # # TODO: 去除循环\n",
    "        # for i in range(bsz):\n",
    "        #     for j in range(seq_len):\n",
    "        #         weight_sparse[i, j, idx[i,j]] = weight[i, j, idx[i,j]]\n",
    "        # weight_sparse /= weight_sparse.sum(dim = -1, keepdim=True) # 归一化\n",
    "        weight_sparse.scatter_(-1, idx, v)\n",
    "        weight_sparse /= weight_sparse.sum(dim = -1, keepdim=True).clamp_min(1e-12) # 归一化\n",
    "\n",
    "        \n",
    "        print('专家归一化权重:', weight_sparse)\n",
    "        \n",
    "        output = torch.zeros_like(x)\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            output += weight_sparse[...,i].unsqueeze(-1) * expert(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "k = 2\n",
    "smoe = MoESparse(dim=dim, num_experts=num_experts, topk=k)\n",
    "print(smoe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa66c27-dfed-4e67-b179-d5e3b3403f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token选择的专家 id 是不同的: tensor([[[2, 3],\n",
      "         [4, 3],\n",
      "         [1, 7]],\n",
      "\n",
      "        [[0, 5],\n",
      "         [7, 4],\n",
      "         [0, 2]]])\n",
      "专家归一化权重: tensor([[[0.0000, 0.0000, 0.6649, 0.3351, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4914, 0.5086, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6973, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3027]],\n",
      "\n",
      "        [[0.5072, 0.0000, 0.0000, 0.0000, 0.0000, 0.4928, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.0000, 0.0000, 0.5647],\n",
      "         [0.5771, 0.0000, 0.4229, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "torch.Size([2, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "Y = smoe(X)\n",
    "print(Y.shape)\n",
    "\n",
    "# top-k 算子是不可微的, backward 成功\n",
    "loss = Y.mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90efa65-2dc5-474f-88b6-218a638aa55a",
   "metadata": {},
   "source": [
    "上述代码打印了 top-k 专家。 总共 2x3=6 个token，每个 token 所选择的专家 id 是不一样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31886eec-4213-4966-91ef-c7bbe20fdc31",
   "metadata": {},
   "source": [
    "## SMoE 减少计算量\n",
    "\n",
    "在上述实现中，虽然top-k筛选了专家，非top-k专家仍参与了计算（没有意义，其权值为0)\n",
    "\n",
    "为了减少计算量，只计算 top-k 专家的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff9178e-6375-485c-aaa4-3763dea4c842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoESparseEfficient(\n",
      "  (experts): ModuleList(\n",
      "    (0-7): 8 x Expert(\n",
      "      (w): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gate): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MoESparseEfficient(MoEBasic):\n",
    "    def __init__(self, dim=512, num_experts=8, topk = 2):\n",
    "        super().__init__()\n",
    "        self.topk = 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, _ = x.shape\n",
    "        weight = self.gate(x)\n",
    "        weight = F.softmax(weight, dim = -1) # bsz, seq_len, num_experts\n",
    "\n",
    "        # process top-k index\n",
    "        v, idx = torch.topk(weight, dim = -1, k=self.topk)\n",
    "        v /= v.sum(dim = -1, keepdim=True)\n",
    "\n",
    "        output = torch.zeros_like(x)\n",
    "        \n",
    "        # token-wise for-loop \n",
    "        for i in range(bsz):\n",
    "            for j in range(seq_len):\n",
    "                for k in range(self.topk):\n",
    "                    # 共调用 bsz*seq_len*topk次专家\n",
    "                    expert_id = idx[i,j,k]\n",
    "                    output[i,j,:] += v[i,j,k] * self.experts[expert_id]( x[i,j,:])\n",
    "                    \n",
    "        return output\n",
    "\n",
    "# k = 2\n",
    "smoe_forloop = MoESparseEfficient(dim=dim, num_experts=num_experts, topk=k)\n",
    "print(smoe_forloop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55755226-4bb2-434b-85d7-ba0f2eaa6383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "Y = smoe_forloop(X)\n",
    "print(Y.shape)\n",
    "\n",
    "# top-k 算子是不可微的, backward 成功\n",
    "loss = Y.mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24742684-1c29-4867-98da-29f4d1d77d4c",
   "metadata": {},
   "source": [
    "## SMoE dispatch mode\n",
    "\n",
    "上述 forward 实现中, token-level forward 计算低效。 \n",
    "\n",
    "|              | E1      | E2      | E3          | E4        |\n",
    "| ------------ | ------- | ------- | ----------- | --------- |\n",
    "| Token 1      | 1       | 0       | 1           | 0         |\n",
    "| Token 2      | 0       | 0       | 1           | 1         |\n",
    "| Token 3      | 0       | 1       | 1           | 1         |\n",
    "| **dispatch** | Token 1 | Token 3 | Token 1,2,3 | Token 2,3 |\n",
    "\n",
    "从 expert 的视角，如 E4 可以一次性 forward token1, 2,3。\n",
    "\n",
    "从forloop版本实现思路，变为调用 `num_experts` 次专家 forward\n",
    "\n",
    "E4 forward 得到 `E4 = [3, dim]`\n",
    "E2 forward 得到 `E2 = [1, dim]`\n",
    "\n",
    "对于 token2 的输出为 `weight[1, 1]*E2[0,:] + weight[1, 0]*E4[1,:]` #token2 top-k 专家ID 为 `[E4, E2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8226292-6aab-4591-8cd4-b714ce185598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2],\n",
      "        [1, 3],\n",
      "        [0, 0]])\n",
      "(tensor([2, 2]), tensor([0, 1]))\n",
      "(tensor([1]), tensor([0]))\n",
      "(tensor([0, 0]), tensor([0, 1]))\n",
      "(tensor([1]), tensor([1]))\n"
     ]
    }
   ],
   "source": [
    "idx = torch.randint(4, (3,2))\n",
    "print(idx)\n",
    "print(torch.where(idx == 0))\n",
    "print(torch.where(idx == 1))\n",
    "print(torch.where(idx == 2))\n",
    "print(torch.where(idx == 3))\n",
    "\n",
    "# 注意：有的专家未被任何token选择到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e46eb717-8955-430e-9289-916b2c829724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def is_empty_expert(idx):\n",
    "    return len(idx.tolist()) == 0\n",
    "print( is_empty_expert( torch.tensor([]) ))\n",
    "print( is_empty_expert( torch.tensor([1]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47fd4cd4-fbc0-44e9-861b-1dd5b8fc4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoESparseExpertLoop(\n",
      "  (experts): ModuleList(\n",
      "    (0-7): 8 x Expert(\n",
      "      (w): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gate): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MoESparseExpertLoop(MoEBasic):\n",
    "    def __init__(self, dim=512, num_experts=8, topk = 2):\n",
    "        super().__init__()\n",
    "        self.topk = 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, dim = x.shape\n",
    "        N = bsz * seq_len \n",
    "        x = x.view(N, dim) #共有 N 个 token\n",
    "\n",
    "        weight = self.gate(x)\n",
    "        weight = F.softmax(weight, dim = -1) # bsz, seq_len, num_experts\n",
    "\n",
    "        # process top-k index\n",
    "        v, idx = torch.topk(weight, dim = -1, k=self.topk)\n",
    "        v /= v.sum(dim = -1, keepdim=True)\n",
    "        print(idx)\n",
    "        print(v)\n",
    "\n",
    "        token_to_expert = [None] * self.num_experts\n",
    "        for i in range(self.num_experts):\n",
    "            token_id = torch.where(idx == i) # dim 0 is token id\n",
    "            if is_empty_expert(token_id[0]):\n",
    "                continue\n",
    "            token_to_expert[i] = token_id\n",
    "            \n",
    "        output = torch.zeros_like(x)\n",
    "        for i in range(self.num_experts):\n",
    "            if token_to_expert[i] is None:\n",
    "                print('expert ', i, ' **empty select token**')\n",
    "                continue\n",
    "            cur_token = token_to_expert[i][0]\n",
    "            cur_weight = v[token_to_expert[i][0], token_to_expert[i][1]] \n",
    "            dispatch_x = x[cur_token, :]\n",
    "            \n",
    "            print('expert:', i,'select_token:', cur_token, '\\t\\tcur weight:', cur_weight)\n",
    "            output[cur_token, :] += cur_weight.unsqueeze(-1) * self.experts[i](dispatch_x)\n",
    "\n",
    "        return output.reshape(bsz, seq_len, dim), idx, v, token_to_expert\n",
    "\n",
    "# k = 2\n",
    "smoe_eloop = MoESparseExpertLoop(dim=dim, num_experts=num_experts, topk=k)\n",
    "print(smoe_eloop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10e80845-fac2-4d8e-b1b0-5bbe9e36da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 6],\n",
      "        [7, 5],\n",
      "        [6, 2],\n",
      "        [4, 2],\n",
      "        [3, 1],\n",
      "        [1, 3]])\n",
      "tensor([[0.5352, 0.4648],\n",
      "        [0.6510, 0.3490],\n",
      "        [0.6306, 0.3694],\n",
      "        [0.5105, 0.4895],\n",
      "        [0.6084, 0.3916],\n",
      "        [0.5695, 0.4305]], grad_fn=<DivBackward0>)\n",
      "expert  0  **empty select token**\n",
      "expert: 1 select_token: tensor([4, 5]) \t\tcur weight: tensor([0.3916, 0.5695], grad_fn=<IndexBackward0>)\n",
      "expert: 2 select_token: tensor([2, 3]) \t\tcur weight: tensor([0.3694, 0.4895], grad_fn=<IndexBackward0>)\n",
      "expert: 3 select_token: tensor([4, 5]) \t\tcur weight: tensor([0.6084, 0.4305], grad_fn=<IndexBackward0>)\n",
      "expert: 4 select_token: tensor([3]) \t\tcur weight: tensor([0.5105], grad_fn=<IndexBackward0>)\n",
      "expert: 5 select_token: tensor([1]) \t\tcur weight: tensor([0.3490], grad_fn=<IndexBackward0>)\n",
      "expert: 6 select_token: tensor([0, 2]) \t\tcur weight: tensor([0.4648, 0.6306], grad_fn=<IndexBackward0>)\n",
      "expert: 7 select_token: tensor([0, 1]) \t\tcur weight: tensor([0.5352, 0.6510], grad_fn=<IndexBackward0>)\n",
      "torch.Size([2, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(bsz, seq_len, dim)\n",
    "Y, idx, weight, token_to_expert = smoe_eloop(X)\n",
    "print(Y.shape)\n",
    "\n",
    "# # top-k 算子是不可微的, backward 成功\n",
    "loss = Y.mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226faac-3a6e-4c68-9845-109b6e8dd0fa",
   "metadata": {},
   "source": [
    "## SMoE dispatch-combine mode\n",
    "\n",
    "简化代码实现，实现3段式 smoe\n",
    "\n",
    "1. dispatch\n",
    "2. compute\n",
    "3. combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2941202d-c93e-4af4-a2d8-5a60945043a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SMoEOuput:\n",
    "#     gates = None\n",
    "#     weight = None\n",
    "#     v = None\n",
    "#     idx = None\n",
    "#     token_to_expert = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75488024-5717-4bcf-8662-c747d1889aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseMixtreOfExpert(\n",
      "  (experts): ModuleList(\n",
      "    (0-7): 8 x Expert(\n",
      "      (w): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gate): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SparseMixtreOfExpert(MoEBasic):\n",
    "    def __init__(self, dim=512, num_experts=8, topk = 2):\n",
    "        super().__init__()\n",
    "        self.topk = 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, dim = x.shape\n",
    "        N = bsz * seq_len \n",
    "        x = x.view(N, dim) #共有 N 个 token\n",
    "\n",
    "        # 0. gate\n",
    "        gates = self.gate(x)\n",
    "        weight = F.softmax(gates, dim = -1) # bsz, seq_len, num_experts\n",
    "        v, idx = torch.topk(weight, dim = -1, k=self.topk)\n",
    "        v /= v.sum(dim = -1, keepdim=True)\n",
    "\n",
    "        # 1. dispatch\n",
    "        token_to_expert = [None] * self.num_experts\n",
    "        for i in range(self.num_experts):\n",
    "            token_id = torch.where(idx == i) # dim 0 is token id\n",
    "            if is_empty_expert(token_id[0]):\n",
    "                continue\n",
    "            token_to_expert[i] = token_id\n",
    "\n",
    "        # 2. compute\n",
    "        dispatch_y = [None] * self.num_experts\n",
    "        for i in range(self.num_experts):\n",
    "            if token_to_expert[i] is not None:\n",
    "                cur_token = token_to_expert[i][0]\n",
    "                dispatch_x = x[cur_token, :]\n",
    "                dispatch_y[i] = self.experts[i](dispatch_x)\n",
    "\n",
    "        # 3. combine\n",
    "        y = torch.zeros_like(x)\n",
    "        for i in range(self.num_experts):\n",
    "            if dispatch_y[i] is not None:\n",
    "                cur_weight = v[token_to_expert[i][0], token_to_expert[i][1]]\n",
    "                y[token_to_expert[i][0], :] += cur_weight.unsqueeze(dim = -1) * dispatch_y[i]\n",
    "\n",
    "        # 4. reshape y\n",
    "        y = y.reshape(bsz, seq_len, dim)\n",
    "\n",
    "        return y, token_to_expert, v\n",
    "\n",
    "my_moe = SparseMixtreOfExpert(dim=dim, num_experts=num_experts, topk=k)\n",
    "print(my_moe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e48bc2-3866-4d8f-b45a-6d964f91b9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(bsz, seq_len, dim)\n",
    "Y, _, _ = my_moe(X)\n",
    "print(Y.shape)\n",
    "\n",
    "# # top-k 算子是不可微的, backward 成功\n",
    "loss = Y.mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c5dada-4e4b-47b1-bb52-a80d09f4deed",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "1. LLM 的 sMoE 可以由多个 FFN 与 1 个门控网络组成，其输出特征是一种集成特征\n",
    "3. 每个 token 根据门控选择到不同的专家\n",
    "4. sMoE 是扩展模型参数同时减少计算量行之有效的做法\n",
    "5. 分析 sMoE 的参数量，激活参数量\n",
    "\n",
    "讨论：\n",
    "\n",
    "1. 专家之间输出是否有冗余，sMoE 当前的 top-k 中的 k 是固定的，能否 k 也是一个 adaptive 的，例如 top-p 专家？\n",
    "2. sMoE 中有 gate， 而 swiglu 中有 GLU， 分析二者的门控差异？\n",
    "3. 如果将 sMoE 看作是专家特征加权组合，分析此加权组合 与 注意力加权组合有什么差异？\n",
    "4. 如果 expert 之间差异非常大， 是否 gate 存在小的偏移，就导致 sMoE 最终输出的特征存在巨大变化？\n",
    "5. 设计一个带 sparse gate 的 attention 组件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
