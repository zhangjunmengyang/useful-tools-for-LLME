{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6f1387-6d6b-43de-acb9-98265cdaac18",
   "metadata": {},
   "source": [
    "# sMoE 负载均衡\n",
    "\n",
    "\n",
    "训练 sMoE 遇到新的问题：\n",
    "\n",
    "1. 当 gate 网络选择 sparse expert，非 top-k 专家梯度为 0，在训练过程中，专家分布不均衡，导致 MoE 并未达到设计目的\n",
    "2. top-k 无法求导（上述实现时 torch 的 top-k 内部采用了一种离散的求导机制）\n",
    "\n",
    "问题1中，可以设计一种 load balance（负载均衡）机制，来保证 sMoE 中各专家都能够充分的参与训练。\n",
    "\n",
    "1. 浅显的均衡可以理解，每个专家所处理的 token 数量是均匀的，设 token 数量为 20, top-k 为 2, 对于 8 个 expert, 每个专家平均处理 `20*2/8=5` 个 token\n",
    "2. 需要定义统计量来分析稀疏专家的均衡性\n",
    "\n",
    "在训练过程中，可以定义出一个负载均衡 loss 项，来保证均衡性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcdb38d-efc4-488c-878c-697dcfeba092",
   "metadata": {},
   "source": [
    "## Sparse Gate\n",
    "\n",
    "最简带负载均衡的 Sparse Gate 实现思路：\n",
    "\n",
    "1. 统计各专家分配的 token 数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7821e7a2-a3a9-4553-8da5-8afb4ddaafd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x118ab8db0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8bf253-a6bd-4ce2-8e6b-dca8f6a1487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseGate(nn.Module):\n",
    "    def __init__(self, dim=512, num_experts=8, topk=2):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_experts = num_experts\n",
    "        self.topk = topk\n",
    "        self.gate = nn.Linear(self.dim, self.num_experts)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bsz, seq_len, dim = x.shape\n",
    "        x=x.view(bsz*seq_len, dim)\n",
    "\n",
    "        # gate topk\n",
    "        gates = self.gate(x)\n",
    "        weight = F.softmax(gates, dim = -1)\n",
    "        v, idx = torch.topk(weight, dim = -1, k=self.topk)\n",
    "        v /= v.sum(dim = -1, keepdim=True)\n",
    "\n",
    "        # counts\n",
    "        counts = [0] * self.num_experts\n",
    "        for i in range(self.num_experts):\n",
    "            counts[i] = len(torch.where(idx == i)[0].tolist())\n",
    "            \n",
    "        return counts, weight, idx, v\n",
    "dim=512\n",
    "num_experts=8\n",
    "k=2\n",
    "sGate = SparseGate(dim=dim, num_experts=num_experts, topk=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55536ebf-4e9d-4890-a9b9-87336481aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz=2\n",
    "seq_len=10\n",
    "n_tokens=bsz*seq_len\n",
    "\n",
    "x=torch.randn(bsz, seq_len, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d59062a-9650-4f41-b2d1-e30127305e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 8, 7, 4, 8, 1, 3, 6]\n"
     ]
    }
   ],
   "source": [
    "counts, weight, idx, v = sGate(x)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83ca58b-203e-43e7-a31a-c38cde6a8141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n",
      "tensor(24.2500)\n"
     ]
    }
   ],
   "source": [
    "def loss_balance_basic(counts):\n",
    "    c = torch.tensor(counts, dtype=torch.float)\n",
    "    loss = ((c-c.mean())**2).mean()\n",
    "    return loss\n",
    "    \n",
    "loss = loss_balance_basic(counts)\n",
    "print(loss)\n",
    "\n",
    "# 定义极不平衡的 expert 处理的 token 数量分布, loss 非常大\n",
    "dummy_counts = [1,1,1,16,1,1,1,2]\n",
    "print(loss_balance_basic(dummy_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93133c17-5732-4b30-97a3-e210009b7acc",
   "metadata": {},
   "source": [
    "## load balance 指标\n",
    "\n",
    "上述计算规则较简单，仅考虑统计数量。回到混合专家输出，其最终输出还与 sparse gate weight $g_i$ 有关\n",
    "\n",
    "$$\n",
    "o = \\sum_i^N g_i E_i(x)\n",
    "$$\n",
    "\n",
    "例如, top-2 的权重分别为 `(0.9,0.1)` 就不如 `(0.45,0.55)`. \n",
    "\n",
    "综上考虑负载均衡：\n",
    "\n",
    "1. 每个 expert 处理的 token 数量平衡\n",
    "2. 每个 expert 分配的 weight 平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3147d5-161b-49d1-8418-4ec62cc2bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(1, 5, dim)\n",
    "counts, weight, idx, v =sGate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15fec12d-cca0-416e-86c9-66ea64a544ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 1, 0, 0, 0]])\n",
      "tensor([[0.0000, 0.0000, 0.4731, 0.0000, 0.5269, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3119, 0.0000, 0.6881],\n",
      "        [0.5515, 0.0000, 0.4485, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4695, 0.0000, 0.5305, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4544, 0.0000, 0.5456, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "def sparse_to_matrix(idx, weight, n_experts=8):\n",
    "    N, k = idx.shape\n",
    "    mat_idx = torch.zeros(N,n_experts)\n",
    "    mat_weight = torch.zeros(N,n_experts)\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            mat_idx[i, idx[i, j]] = 1\n",
    "            mat_weight[i, idx[i, j]] = weight[i,j]\n",
    "    return mat_idx, mat_weight\n",
    "\n",
    "idx_mat, weight_mat = sparse_to_matrix(idx, v)\n",
    "print(idx_mat.to(torch.long))\n",
    "print(weight_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc0ade-7a76-4d68-bdcd-1241586e9060",
   "metadata": {},
   "source": [
    "根据 \n",
    "\n",
    "> sMoE Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\n",
    "\n",
    "其负载均衡损失为：\n",
    "\n",
    "\\begin{equation}\n",
    "Importance(X) = \\sum_{x \\in X}G(x)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "L_{importance}(X) = w_{importance} \\cdot CV(Importance(X))^2\n",
    "\\end{equation}\n",
    "\n",
    "定义： 专家重要性指标 importance, 如果某个专家被频繁选中或权重更大，其对 MoE 特征贡献越大\n",
    "\n",
    "Coefficient of Variation（变异系数）。它是衡量数据相对离散程度的标准化统计量。\n",
    "\n",
    "CV 为标准差相对于平均值有多大:\n",
    "\n",
    "$$\n",
    "cv = \\frac{\\mu}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438f84e3-d714-4320-8107-06e688e3ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 3., 1., 2., 1., 0., 1.])\n",
      "tensor([0.5515, 0.4695, 1.3760, 0.5305, 1.0725, 0.3119, 0.0000, 0.6881],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def importance(x):\n",
    "    return x.sum(dim=0)\n",
    "    \n",
    "print(importance(idx_mat))\n",
    "print(importance(weight_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20212d3-daef-4037-abc5-99ec773a570a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4737, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def CoefficientVariation(x):\n",
    "    return x.std()/x.mean()\n",
    "\n",
    "imp = importance(weight_mat)\n",
    "cv = CoefficientVariation(imp)\n",
    "# print(cv)\n",
    "print(cv**2) # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "777f4109-1961-443d-9027-2752ca0fef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4749)\n",
      "tensor(0.0816)\n"
     ]
    }
   ],
   "source": [
    "imp1 = torch.tensor([3,0.7,0, 0.1])\n",
    "imp2 = torch.tensor([1.1,1,1, 0.9])\n",
    "print(CoefficientVariation(imp1))\n",
    "print(CoefficientVariation(imp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f97a770-d2e0-423a-89ed-1d5fe99bda6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2271, grad_fn=<PowBackward0>)\n",
      "tensor(0.4051, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def load_balance_loss_smoe(idx, weight, n_experts):\n",
    "    idx_mat, weight_mat = sparse_to_matrix(idx, weight, n_experts)\n",
    "    imp = importance(weight_mat)\n",
    "    cv = CoefficientVariation(imp)\n",
    "    return cv**2\n",
    "\n",
    "x=torch.randn(1, 2, dim)\n",
    "_, _, idx, v =sGate(x)\n",
    "loss = load_balance_loss_smoe(idx, v, num_experts)\n",
    "print(loss)\n",
    "\n",
    "x=torch.randn(1, 10, dim) \n",
    "_, _, idx, v =sGate(x)\n",
    "loss = load_balance_loss_smoe(idx, v, num_experts)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ff313-e769-4c71-8391-c68dc25bdb1d",
   "metadata": {},
   "source": [
    "由于模型参数是随机化的\n",
    "\n",
    "bsz * seq_len 越大, 每个专家分配越均匀，loss越小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7f33b-8125-4b94-a8da-17e3a1b2c941",
   "metadata": {},
   "source": [
    "## 定量分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8b88de-dca3-4aeb-b42e-0ea768761bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0965)\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "num_experts = 8\n",
    "\n",
    "\n",
    "gates = torch.randn(N, num_experts)\n",
    "\n",
    "def gate_function(gates, k, num_experts):\n",
    "    weight = F.softmax(gates, dim = -1)\n",
    "    v, idx = torch.topk(weight, dim = -1, k=k)\n",
    "    v /= v.sum(dim = -1, keepdim=True)\n",
    "    return idx, v\n",
    "\n",
    "gates = torch.randn(N, num_experts)\n",
    "idx, v = gate_function(gates, k, num_experts)\n",
    "loss = load_balance_loss_smoe(idx, v, num_experts)\n",
    "# print(idx)\n",
    "# print(v)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ce7d7e8-608d-4741-855d-84d4ff5c4494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7825)\n",
      "tensor(1.1264)\n"
     ]
    }
   ],
   "source": [
    "gates10 = gates.clone()\n",
    "gates10[:, 3] = gates[:, 3] * 10 # 专家 3 门控放大\n",
    "idx, v = gate_function(gates10, k, num_experts)\n",
    "loss = load_balance_loss_smoe(idx, v, num_experts)\n",
    "print(loss)\n",
    "\n",
    "gates100 = gates.clone()\n",
    "gates100[:, 3] = gates[:, 3] * 100 # 专家 3 门控放大\n",
    "idx, v = gate_function(gates100, k, num_experts)\n",
    "loss = load_balance_loss_smoe(idx, v, num_experts)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b597858-f107-4d6d-882a-f7c4816b6ad8",
   "metadata": {},
   "source": [
    "## Switch Transformer load balance\n",
    "\n",
    "当前流行 loss 版本来自 Switch Transformer (Noam Shazeer), 其负载均衡综合考虑各专家处理token数量和权重\n",
    "\n",
    "> Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,\n",
    "\n",
    "$$\n",
    "\\text{loss} = \\alpha \\cdot N \\cdot \\sum_{i=1}^{N} f_i \\cdot P_i\n",
    "$$\n",
    "\n",
    "其中, $N$ 为专家数量\n",
    "\n",
    "$$\n",
    "f_i = \\frac{1}{T} \\sum_{x \\in \\mathcal{B}} 1\\{\\text{argmax } p(x) = i\\}\n",
    "$$\n",
    "    \n",
    "其中, $T$ 为 token 数量, $\\mathcal{B}$ 为批次上所有 token, $\\text{argmax} p(x) = i$ 表示token $x$ 权重最大对应 $i$ 专家, 由于 Switch Transfomrer，选top-1专家，通用写法可以为 $\\text{top-k} p(x) = i$, $f_i$ 表示专家 $i$ 处理的 tokens 的比例\n",
    "\n",
    "$$\n",
    "P_i = \\frac{1}{T} \\sum_{x \\in \\mathcal{B}} p_i(x)\n",
    "$$\n",
    "\n",
    "其中，$P_i$ 表示专家 $i$ 处理的累积的权重和（重要性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442a591b-984e-4880-99b8-77b5378594fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1702)\n"
     ]
    }
   ],
   "source": [
    "def load_balance_loss_switch(idx, weight, n_experts):\n",
    "    N, k = idx.shape\n",
    "    \n",
    "    idx_mat, weight_mat = sparse_to_matrix(idx, weight, n_experts)\n",
    "\n",
    "    fi = idx_mat.mean(dim = 0)\n",
    "    pi = weight_mat.mean(dim = 0)\n",
    "\n",
    "    return n_experts * (fi * pi).sum()\n",
    "    \n",
    "idx, v = gate_function(gates, k, num_experts)\n",
    "loss = load_balance_loss_switch(idx, v, num_experts)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2b37acc-e8c7-4cbd-a865-cec57a17f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5607)\n",
      "tensor(2.7190)\n"
     ]
    }
   ],
   "source": [
    "gates10 = gates.clone()\n",
    "gates10[:, 3] = gates[:, 3] * 10 # 专家 3 门控放大\n",
    "idx, v = gate_function(gates10, k, num_experts)\n",
    "loss = load_balance_loss_switch(idx, v, num_experts)\n",
    "print(loss)\n",
    "\n",
    "gates100 = gates.clone()\n",
    "gates100[:, 3] = gates[:, 3] * 100 # 专家 3 门控放大\n",
    "idx, v = gate_function(gates100, k, num_experts)\n",
    "loss = load_balance_loss_switch(idx, v, num_experts)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd793f-a8bb-4299-8c50-20638e1c5e58",
   "metadata": {},
   "source": [
    "## 讨论\n",
    "\n",
    "1. 负载均衡对 sMoE 系统至关重要，在训练中, 能够避免陷入单一专家计算\n",
    "2. MoE 训练系统中，有一种并行技术称之为专家并行，即每个设备加载其中 1 个专家，负载均衡目标使得各设备计算-通信都是平衡的\n",
    "3. switch transformer 版本可以理解为： 带派发比例的权重重要性指标\n",
    "\n",
    "另外讨论两种 case：\n",
    "\n",
    "1. 在 transformer 中，有多层block，每层block都有一个 sMoE 组件，此时负载均衡是根据 block-wise 算，还是 model-wise 计算？\n",
    "2. 本 notebook 分析的负载均衡是基于 batch-wise 计算的， 分析 llm 场景采用 sequence-level 计算的合理性\n",
    "\n",
    "思考 load_balance_loss 的反向传播如何计算？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98700c08-00da-4cb3-bce3-6874eb79261a",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
