{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd937675-335d-4e03-9ce9-744435f53a6f",
   "metadata": {},
   "source": [
    "# SFT by PyTorch\n",
    "\n",
    "本代码基于数据构造 `lecture/lc6_sft/Supervised_Finetuning_Dataset.ipynb`  进行训练。\n",
    "\n",
    "并且本代码可以在 colab/CPU/GPU/Mac 上进行微调训练。本代码在 mac 运行，所微调模型能正常对话。\n",
    "\n",
    "本代码自定义 dataset 和 训练函数，训练成功后能进行文本生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffc62c-571a-419f-bfc1-dedbb22f30e4",
   "metadata": {},
   "source": [
    "关于 `transfomrers` 库的使用，建议以[官网文档](https://huggingface.co/docs/transformers/index)为主，查阅接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54d8c8ae-403f-49c9-83dc-1d2433c5628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-0.6B', \n",
    "                                          local_dir='~/.cache/huggingface/', # 如果可以直连 huggingface, 去除此行.\n",
    "                                         )\n",
    "\n",
    "## 调用现成 Pretrained 模型, 进行全参微调\n",
    "model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen3-0.6B',\n",
    "                                             local_files_only=True, )\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7c3db2e-b6fe-4875-9a35-6547981d6d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 151936])\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "dummy_input_ids = torch.randint(100,(2,3))\n",
    "\n",
    "output = model(input_ids=dummy_input_ids)\n",
    "print(output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2adafacb-021e-4923-8f96-6e7405a52725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100007, 100134,  12669,     30]])\n",
      "如何学习python? 有哪些资源推荐？ 有哪些书籍推荐？ 有哪些在线课程？ 有哪些工具推荐？ 有哪些社区？ 有哪些学习计划？ 有哪些学习方法？ 有哪些学习资源？ 有哪些学习工具？ 有哪些学习社区？ 有哪些学习计划？ 有哪些学习方法？ 有哪些学习资源？ 有哪些学习工具？ 有哪些学习社区？ 有哪些学习计划？ 有哪些学习方法？ 有哪些学习资源？ 有哪些学习工具？ 有哪些学习社区？ 有哪些学习计划？ 有哪些学习方法？ 有哪些学习资源？ 有哪些学习工具？ 有哪些学习社区？ 有哪些学习计划\n"
     ]
    }
   ],
   "source": [
    "# Genreation\n",
    "\n",
    "input_ids = tokenizer(['如何学习python?'], return_tensors='pt')['input_ids']\n",
    "print(intput_ids)\n",
    "output_ids = model.generate(\n",
    "    input_ids, \n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    "    temperature=1.0\n",
    ")\n",
    "result = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d71f97-117e-45bb-a8c4-e7eae018bfa7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. 预训练模型一般出现重复输出或者是不停止的情况，常被称为“复读机”现象\n",
    "3. 原因在于预训练数据不是每条都有 <EOS> 的\n",
    "4. 思考：有什么方法可以使得预训练模型按照我们期望能够正常回答问题(能够有逻辑输出并能预测 eos)\n",
    "\n",
    "以下代码将基于 “指令数据” 微调预训练模型，使微调后的模型具有 “指令跟随能力”，即能正常回答“通用”问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e0527-962c-41ea-9118-a7e43bc94d5f",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b71ac260-2d93-4282-a1a4-dbdee12bac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'text'],\n",
      "        num_rows: 52002\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('tatsu-lab/alpaca',\n",
    "                       # data_dir='default',\n",
    "                      cache_dir=\"~/.cache/huggingface\",)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c013b5c3-9a4d-43db-9b06-818b2e421422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<instruction> Give three tips for staying healthy.\n",
      "<input> \n",
      "<output> 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n",
      "2. Exercise regularly to keep your body active and strong. \n",
      "3. Get enough sleep and maintain a consistent sleep schedule.\n"
     ]
    }
   ],
   "source": [
    "print('<instruction>',dataset['train'][0]['instruction'])\n",
    "print('<input>',dataset['train'][0]['input'])\n",
    "print('<output>',dataset['train'][0]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "402a3d69-456e-418c-9846-0ed859c51e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFINED_EOS_TOKEN = '<|im_end|>'\n",
    "DEFINED_SOS_TOKEN = '<|im_start|>'\n",
    "DEFINED_PAD_TOKEN = '<|endoftext|>'\n",
    "DEFINIED_SYSTEM_PROMPT='你是小冬瓜智能体,请安全详细回答用户 USER 的问题'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1752cfcd-d9ef-424a-bf93-604ecad237bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_messageslist(dataset):\n",
    "    messages = []\n",
    "    for item in dataset['train']:\n",
    "        messages_inst = [\n",
    "            {'role':'SYSTEM', 'content':DEFINIED_SYSTEM_PROMPT},\n",
    "            {'role':'USER', 'content': item['instruction'] + item['input'] },\n",
    "            {'role':'ASSISTANT', 'content': item['output'] },\n",
    "        ]\n",
    "        messages.append(messages_inst)\n",
    "    return messages\n",
    "dataset_instruction = dataset_to_messageslist(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1c61b69-d43e-4618-9260-995fe1e88d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'SYSTEM', 'content': '你是小冬瓜智能体,请安全详细回答用户 USER 的问题'}, {'role': 'USER', 'content': 'Give three tips for staying healthy.'}, {'role': 'ASSISTANT', 'content': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}]\n",
      "[151644, 198, 2, 46487, 25, 105043, 30709, 99949, 100857, 100168, 31914, 11, 14880, 99464, 100700, 102104, 20002, 13872, 43589, 86119, 198, 2, 6448, 25, 35127, 2326, 10414, 369, 19429, 9314, 13, 198, 2, 4939, 3846, 2821, 25, 16, 5142, 266, 264, 23831, 9968, 323, 1281, 2704, 311, 2924, 11260, 315, 25322, 323, 23880, 13, 715, 17, 13, 32818, 15502, 311, 2506, 697, 2487, 4541, 323, 3746, 13, 715, 18, 13, 2126, 3322, 6084, 323, 10306, 264, 12966, 6084, 9700, 13, 151645]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "<|im_start|>\n",
      "#SYSTEM:你是小冬瓜智能体,请安全详细回答用户 USER 的问题\n",
      "#USER:Give three tips for staying healthy.\n",
      "#ASSISTANT:1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n",
      "2. Exercise regularly to keep your body active and strong. \n",
      "3. Get enough sleep and maintain a consistent sleep schedule.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "def ChatTemplateToken(example, tokenizer):\n",
    "    sos_token_id = tokenizer(DEFINED_SOS_TOKEN).input_ids[0] \n",
    "    eos_token_id = tokenizer(DEFINED_EOS_TOKEN).input_ids[0] \n",
    "    \n",
    "    input_ids = [ sos_token_id ]\n",
    "    is_labels = [ 0 ]\n",
    "    \n",
    "    for i, item in enumerate(example):\n",
    "        if item['role'] == 'ASSISTANT':\n",
    "            prompt = '\\n#' + item['role'] + ':'\n",
    "            content_prompt = item['content'] \n",
    "            prompt_token_ids = tokenizer(prompt).input_ids\n",
    "            content_prompt = tokenizer(content_prompt).input_ids\n",
    "\n",
    "            is_labels += [0]*len(prompt_token_ids) + [1]*len(content_prompt) + [1] # last [1] is eos \n",
    "            input_ids += prompt_token_ids + content_prompt + [eos_token_id]\n",
    "            \n",
    "        else:\n",
    "            prompt = '\\n#' + item['role'] + ':' + item['content'] \n",
    "            prompt_token_ids = tokenizer(prompt).input_ids\n",
    "            input_ids += prompt_token_ids\n",
    "            \n",
    "            is_labels += [0]*len(prompt_token_ids)\n",
    "            \n",
    "    return input_ids, is_labels\n",
    "    \n",
    "print(dataset_instruction[0])\n",
    "prompt, is_label = ChatTemplateToken(dataset_instruction[0], tokenizer)\n",
    "print(prompt)\n",
    "print(is_label)\n",
    "print(tokenizer.decode(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98ab0b39-4262-484b-9482-02ad2954f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TokenSFTDataset(Dataset):\n",
    "    def __init__(self, messages_list, tokenizer):\n",
    "        data_list = [ ChatTemplateToken(messages, tokenizer) for messages in messages_list ]\n",
    "        self.data = []\n",
    "        for data in data_list:\n",
    "            self.data.append( \n",
    "                [torch.tensor(data[0], dtype=torch.long), \n",
    "                 torch.tensor(data[1], dtype=torch.long)]\n",
    "            )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        token 返回数据一般是 tensor\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'input_ids': self.data[idx][0],\n",
    "            'is_label':self.data[idx][1]\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de1049d5-3c5f-43cc-b82f-b7b491c21a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddding_collate_fn(batch_data, pad_token_id=None, ignore_index=-100):\n",
    "\n",
    "    input_lens = []\n",
    "    label_lens = []\n",
    "    bs = len(batch_data)\n",
    "\n",
    "    # padding longest maxlen\n",
    "    for data in batch_data:\n",
    "        input_lens.append(data['input_ids'].shape[0])\n",
    "        max_input_len = torch.max(torch.tensor(input_lens, dtype=torch.long))\n",
    "    \n",
    "    # Right Padding\n",
    "    input_ids = torch.ones(bs, max_input_len, dtype=torch.long) * pad_token_id\n",
    "    attention_masks = torch.zeros(bs, max_input_len, dtype=torch.long)\n",
    "    labels = torch.ones(bs, max_input_len, dtype=torch.long) * ignore_index\n",
    "\n",
    "    for i in range(bs):\n",
    "        input_ids[i, :input_lens[i]] = batch_data[i]['input_ids']\n",
    "        attention_masks[i, :input_lens[i]] = 1\n",
    "        \n",
    "        idx = torch.where( batch_data[i]['is_label'] != 0)[0]\n",
    "        labels[i, idx-1] = batch_data[i]['input_ids'][idx]\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_masks': attention_masks,\n",
    "        'labels': labels,\n",
    "    }\n",
    "\n",
    "class PaddingCollateFunction:\n",
    "    def __init__(self, pad_token_id: int, ignore_index: int):\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def __call__(self, batch) -> dict:\n",
    "        batch = paddding_collate_fn(batch, self.pad_token_id, self.ignore_index )\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5c6d14ef-15df-4925-ba68-29fb4dcff6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151643\n"
     ]
    }
   ],
   "source": [
    "DEFINE_IGNORE_INDEX=-100\n",
    "pad_token_id = tokenizer(DEFINED_PAD_TOKEN)[0].ids[0]\n",
    "print(pad_token_id)\n",
    "        \n",
    "dataset_train = TokenSFTDataset(dataset_instruction, tokenizer)\n",
    "collate_fn = PaddingCollateFunction(pad_token_id=pad_token_id, ignore_index=DEFINE_IGNORE_INDEX)\n",
    "\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset_train, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True,\n",
    "                    collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "977a91bf-c29a-412e-8555-d1dde7933c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,  10048,  77990,   6832,    323,   6975,    454,\n",
      "          77990,   6832,    525,   1378,   1887,  19827,    311,   5662,   6832,\n",
      "             13,    220,  61824,   4056,   6832,   7460,  29829,    821,    323,\n",
      "          17167,    315,  25185,    429,    646,   3960,    311,   1281,  19898,\n",
      "            504,    279,   6350,    821,    738,     13,    758,  12872,     11,\n",
      "           6975,    454,  77990,   6832,   1558,    537,   1373,  29829,    821,\n",
      "            323,  17167,    315,  25185,    429,    646,   1477,  12624,    323,\n",
      "          25709,   2041,   3738,  20949,     13, 151645,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100],\n",
      "        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,  15919,    646,  61325,   5577,    311,\n",
      "           3960,    264,    501,   4128,    553,   6243,  88153,   8845,     11,\n",
      "          19429,  10735,     11,    323,  14590,   5577,    448,   4963,     13,\n",
      "          22406,     11,   9271,    264,   4128,   8263,    311,   6588,    448,\n",
      "            476,  18169,    264,   4128,   9289,   1874,    646,   7269,   6832,\n",
      "          19554,     11,    323,  22570,    448,   9867,   4128,  21326,    646,\n",
      "           2968,    825,   1931,  25843,     11,  13922,  11055,     13,  17375,\n",
      "             11,  14289,    311,    323,  10099,   2213,    304,    279,   2169,\n",
      "           4128,    646,   1492,    448,   5810,  74557,    323,  19091,     13,\n",
      "         151645,   -100]])\n"
     ]
    }
   ],
   "source": [
    "# print(dataset_train[0]['is_label'])\n",
    "# for k, batch in enumerate(dataloader):\n",
    "#     print(batch['labels'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2f098c8-342b-4a3b-b733-e3732c1c3df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   4%|=                                | 999/26001 [19:48<8:15:32,  1.19s/it, loss=1.0297]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "\n",
    "learning_rate = 1e-5\n",
    "epochs = 1\n",
    "vocab_size = model.vocab_size\n",
    "grad_accmulative = 10\n",
    "\n",
    "optim = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=DEFINE_IGNORE_INDEX)\n",
    "\n",
    "debug_max_step = 1000\n",
    "total_step = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    # 进度条更新\n",
    "    train_dataloader_tqdm = tqdm(\n",
    "            dataloader,  # 数据加载器\n",
    "            desc=f'Epoch {i+1}/{epochs}',  # 进度条前缀\n",
    "            ncols=100,    # 进度条宽度\n",
    "            ascii=' =',   # ASCII 字符样式\n",
    "        )\n",
    "    \n",
    "    for k, batch in enumerate(train_dataloader_tqdm):\n",
    "        # train step\n",
    "        optim.zero_grad()\n",
    "        bsz, seq_len = batch['input_ids'].shape\n",
    "        output = model(input_ids=batch['input_ids'],\n",
    "                attention_masks=batch['attention_masks'])\n",
    "        logits = output.logits\n",
    "    \n",
    "        loss = loss_fn(logits.view(bsz*seq_len, vocab_size), \n",
    "                       batch['labels'].view(bsz*seq_len)\n",
    "                      )\n",
    "        # print(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # 进度条更新\n",
    "        total_step = total_step + 1\n",
    "        if total_step % 10 == 0:\n",
    "                # print(\n",
    "                # f\"epochs:{i}, step:{total_step}, train_loss: {loss.item()}\")\n",
    "                # tqdm.write(\"\\n\" + \"=\" * 80)\n",
    "            # tqdm.write(f\"Epoch {i+1} | \"\n",
    "            #            f\"Steps {total_step} | \"\n",
    "            #            f\"Loss: {loss.item():.4f} | \")\n",
    "\n",
    "            train_dataloader_tqdm.set_postfix(\n",
    "                loss=f'{loss.item():.4f}',\n",
    "            )\n",
    "        \n",
    "        if total_step == debug_max_step:\n",
    "            break\n",
    "\n",
    "        # test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "952985b4-354d-4fba-a325-7f325e1ee7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100007, 100134,  12669,     30]])\n",
      "如何学习python? 1. 从基础开始，学习Python的语法和基本概念。 2. 学习一些Python库，如NumPy、Pandas、Matplotlib、Scikit-Learn等。 3. 学习一些Python的框架，如NumPy、Scikit-Learn、Pandas、Matplotlib、Scikit-Learn、Pandas、NumPy、Matplotlib、Scikit-Learn、Pandas、NumPy、Scikit-Learn、Pandas、Matplotlib、Scikit-Learn、Pandas、NumPy、Scikit-Learn、Pandas、Matplotlib、Scikit\n"
     ]
    }
   ],
   "source": [
    "# 不带 template\n",
    "input_ids = tokenizer(['如何学习python?'], return_tensors='pt')['input_ids']\n",
    "print(input_ids)\n",
    "output_ids = model.generate(\n",
    "    input_ids, \n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    "    temperature=1.0\n",
    ")\n",
    "result = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa10c2fe-ee2b-4164-828f-d61846048913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_new_tokens=128):\n",
    "    messages_inst = [\n",
    "            {'role':'SYSTEM', 'content':DEFINIED_SYSTEM_PROMPT},\n",
    "            {'role':'USER', 'content': prompt},\n",
    "            {'role':'ASSISTANT', 'content': ''},\n",
    "        ]\n",
    "    input_ids, is_label = ChatTemplateToken(messages_inst, tokenizer)\n",
    "\n",
    "    input_ids = torch.tensor( [input_ids], dtype=torch.long)\n",
    "    input_ids = input_ids[:, :-1] # 去掉 eos \n",
    "    \n",
    "    output_ids = model.generate(\n",
    "        input_ids, \n",
    "        max_new_tokens=128,\n",
    "        do_sample=False,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    result = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return output_ids, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3ac544a-99b3-4fda-b356-ee1c033c5266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#SYSTEM:你是小冬瓜智能体,请安全详细回答用户 USER 的问题\n",
      "#USER:如何学习python?\n",
      "#ASSISTANT:学习Python可以通过阅读书籍、在线课程、实践项目以及参加讨论组。阅读书籍可以帮助理解基本概念和语法，而在线课程可以提供更深入的指导。实践项目可以将所学知识应用到实际问题中，而讨论组则可以提供交流和讨论的平台。\n",
      "torch.Size([1, 95])\n"
     ]
    }
   ],
   "source": [
    "prompt='如何学习python?'\n",
    "output_ids, result = generate(model, tokenizer, prompt, max_new_tokens=128)\n",
    "print(result)\n",
    "print(output_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265fc45-6b1b-4f72-afeb-d183ddeff0e2",
   "metadata": {},
   "source": [
    "## 思考\n",
    "\n",
    "1. 写出批量数据生成代码\n",
    "2. 为什么模型这么小,数据这么少,所训模型生成通用性好\n",
    "3. pretrained模型不能对话，是否就代表它很差？\n",
    "4. 不使用 transformers 库的 generate 函数，写出带 kvcache 的 generate 代码\n",
    "5. 基于 4 进一步写出 right padding 输入 + kvcache + generate 代码\n",
    "6. 如何测评 SFT 模型\n",
    "7. 如何进行更高效的微调？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
