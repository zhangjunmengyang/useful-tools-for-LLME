"""
Beam Search å¯è§†åŒ– - å±•ç¤ºæœç´¢è·¯å¾„æ ‘
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from typing import List, Dict, Any
import torch
from generation_lab.generation_utils import (
    DEMO_MODELS,
    load_model_and_tokenizer
)


def beam_search_with_history(
    model: Any,
    tokenizer: Any,
    prompt: str,
    beam_size: int = 3,
    max_steps: int = 5,
    eos_token_id: int = None
) -> Dict:
    """
    æ‰§è¡Œ Beam Search å¹¶è®°å½•å†å²
    
    Returns:
        åŒ…å«æ¯æ­¥æœç´¢å†å²çš„å­—å…¸
    """
    if eos_token_id is None:
        eos_token_id = tokenizer.eos_token_id
    
    # åˆå§‹åŒ–
    input_ids = tokenizer(prompt, return_tensors="pt")["input_ids"]
    prompt_length = input_ids.shape[1]
    
    # åˆå§‹ beam
    beams = [{
        'ids': input_ids[0].tolist(),
        'score': 0.0,
        'text': prompt,
        'tokens': [],
        'finished': False
    }]
    
    history = {
        'prompt': prompt,
        'beam_size': beam_size,
        'steps': []
    }
    
    for step in range(max_steps):
        step_record = {
            'step': step,
            'active_beams': [],
            'all_candidates': [],
            'pruned': []
        }
        
        all_candidates = []
        
        for beam_idx, beam in enumerate(beams):
            if beam['finished']:
                all_candidates.append({
                    **beam,
                    'new_token': '[EOS]',
                    'new_token_id': eos_token_id,
                    'token_score': 0.0,
                    'parent_idx': beam_idx,
                    'action': 'finished'
                })
                continue
            
            # è·å–ä¸‹ä¸€ä¸ª token çš„åˆ†å¸ƒ
            current_ids = torch.tensor([beam['ids']])
            
            with torch.no_grad():
                outputs = model(current_ids)
                logits = outputs.logits[0, -1, :]
            
            log_probs = torch.log_softmax(logits, dim=-1)
            
            # è·å– top-k å€™é€‰
            top_log_probs, top_indices = torch.topk(log_probs, beam_size * 2)
            
            for i in range(beam_size * 2):
                token_id = top_indices[i].item()
                token_log_prob = top_log_probs[i].item()
                token_str = tokenizer.decode([token_id])
                
                new_ids = beam['ids'] + [token_id]
                new_score = beam['score'] + token_log_prob
                new_text = tokenizer.decode(new_ids[prompt_length:])
                
                candidate = {
                    'ids': new_ids,
                    'score': new_score,
                    'text': prompt + new_text,
                    'tokens': beam['tokens'] + [token_str],
                    'finished': token_id == eos_token_id,
                    'new_token': token_str,
                    'new_token_id': token_id,
                    'token_score': token_log_prob,
                    'parent_idx': beam_idx,
                    'parent_text': ' '.join(beam['tokens']) if beam['tokens'] else '[START]'
                }
                all_candidates.append(candidate)
        
        # æ’åºå¹¶é€‰æ‹© top beam_size
        all_candidates.sort(key=lambda x: x['score'], reverse=True)
        
        # è®°å½•æ‰€æœ‰å€™é€‰
        step_record['all_candidates'] = [{
            'text': c.get('new_token', ''),
            'token_id': c.get('new_token_id', -1),
            'cumulative_score': c['score'],
            'token_score': c.get('token_score', 0),
            'parent': c.get('parent_text', ''),
            'full_sequence': ' '.join(c['tokens'])
        } for c in all_candidates]
        
        # é€‰æ‹©ä¿ç•™çš„ beams
        selected = all_candidates[:beam_size]
        pruned = all_candidates[beam_size:]
        
        step_record['active_beams'] = [{
            'text': s.get('new_token', ''),
            'full_sequence': ' '.join(s['tokens']),
            'cumulative_score': s['score'],
            'probability': np.exp(s['score'])
        } for s in selected]
        
        step_record['pruned'] = [{
            'text': p.get('new_token', ''),
            'full_sequence': ' '.join(p['tokens']),
            'cumulative_score': p['score'],
            'reason': 'score_too_low'
        } for p in pruned[:beam_size]]  # åªè®°å½•å‰å‡ ä¸ªè¢«å‰ªæçš„
        
        history['steps'].append(step_record)
        
        # æ›´æ–° beams
        beams = [{
            'ids': s['ids'],
            'score': s['score'],
            'text': s['text'],
            'tokens': s['tokens'],
            'finished': s['finished']
        } for s in selected]
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ beam éƒ½ç»“æŸ
        if all(b['finished'] for b in beams):
            break
    
    # æœ€ç»ˆç»“æœ
    history['final_beams'] = [{
        'rank': i + 1,
        'sequence': ' '.join(b['tokens']),
        'score': b['score'],
        'probability': np.exp(b['score']),
        'finished': b['finished']
    } for i, b in enumerate(beams)]
    
    return history


def render_beam_tree(history: Dict) -> go.Figure:
    """æ¸²æŸ“ Beam Search æ ‘å½¢å›¾"""
    fig = go.Figure()
    
    beam_size = history['beam_size']
    steps = history['steps']
    
    if not steps:
        return fig
    
    # æ„å»ºèŠ‚ç‚¹
    nodes_x = []
    nodes_y = []
    nodes_text = []
    nodes_color = []
    
    edges_x = []
    edges_y = []
    
    # èµ·å§‹èŠ‚ç‚¹
    nodes_x.append(0)
    nodes_y.append(0)
    nodes_text.append("[START]")
    nodes_color.append('#2563EB')
    
    # è®°å½•æ¯ä¸€æ­¥æ¯ä¸ª beam çš„ä½ç½®
    node_positions = {(0, 0): 0}  # (step, beam_idx) -> node_idx
    
    for step_idx, step in enumerate(steps):
        active_beams = step['active_beams']
        
        for beam_idx, beam in enumerate(active_beams):
            # è®¡ç®—èŠ‚ç‚¹ä½ç½®
            x = step_idx + 1
            y = (beam_idx - len(active_beams) / 2 + 0.5) * 2
            
            node_idx = len(nodes_x)
            node_positions[(step_idx + 1, beam_idx)] = node_idx
            
            nodes_x.append(x)
            nodes_y.append(y)
            nodes_text.append(f"{beam['text']}<br>Score: {beam['cumulative_score']:.2f}")
            nodes_color.append('#2563EB' if beam_idx == 0 else '#60A5FA')
            
            # æ·»åŠ è¾¹ (ä»ä¸Šä¸€æ­¥è¿æ¥)
            if step_idx == 0:
                parent_idx = 0  # ä»èµ·å§‹èŠ‚ç‚¹
            else:
                parent_idx = node_positions.get((step_idx, 0), 0)  # ç®€åŒ–å¤„ç†
            
            edges_x.extend([nodes_x[parent_idx], x, None])
            edges_y.extend([nodes_y[parent_idx], y, None])
    
    # ç»˜åˆ¶è¾¹
    fig.add_trace(go.Scatter(
        x=edges_x,
        y=edges_y,
        mode='lines',
        line=dict(color='#E5E7EB', width=2),
        hoverinfo='none'
    ))
    
    # ç»˜åˆ¶èŠ‚ç‚¹
    fig.add_trace(go.Scatter(
        x=nodes_x,
        y=nodes_y,
        mode='markers+text',
        marker=dict(size=30, color=nodes_color),
        text=[t.split('<br>')[0] for t in nodes_text],
        textposition='top center',
        hovertext=nodes_text,
        hoverinfo='text'
    ))
    
    fig.update_layout(
        title="Beam Search æœç´¢æ ‘",
        showlegend=False,
        xaxis=dict(
            title="Step",
            showgrid=False,
            zeroline=False,
            tickmode='linear',
            tick0=0,
            dtick=1
        ),
        yaxis=dict(
            showgrid=False,
            zeroline=False,
            showticklabels=False
        ),
        height=400,
        margin=dict(l=50, r=50, t=50, b=50)
    )
    
    return fig


def render_step_detail(step_data: Dict) -> None:
    """æ¸²æŸ“å•æ­¥è¯¦æƒ…"""
    st.markdown(f"#### Step {step_data['step'] + 1}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**âœ… ä¿ç•™çš„ Beam**")
        for i, beam in enumerate(step_data['active_beams']):
            score_color = '#059669' if i == 0 else '#2563EB'
            st.markdown(f"""
            <div style="background: #F3F4F6; padding: 10px; border-radius: 6px; margin: 5px 0;
                        border-left: 3px solid {score_color};">
                <b>Beam {i+1}</b>: "{beam['text']}"<br>
                <small>åºåˆ—: {beam['full_sequence'][:50]}...</small><br>
                <small>ç´¯ç§¯åˆ†æ•°: {beam['cumulative_score']:.4f} | 
                       æ¦‚ç‡: {beam['probability']:.2e}</small>
            </div>
            """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("**âŒ è¢«å‰ªæçš„å€™é€‰**")
        if step_data['pruned']:
            for pruned in step_data['pruned'][:3]:
                st.markdown(f"""
                <div style="background: #FEE2E2; padding: 10px; border-radius: 6px; margin: 5px 0;
                            opacity: 0.7;">
                    "{pruned['text']}"<br>
                    <small>åˆ†æ•°: {pruned['cumulative_score']:.4f}</small>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.caption("æ— å‰ªæ")


def render():
    """æ¸²æŸ“é¡µé¢"""
    st.markdown('<h1 class="module-title">Beam Search å¯è§†åŒ–</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="tip-box">
    ğŸ’¡ <b>Beam Search</b> æ˜¯ä¸€ç§å¯å‘å¼æœç´¢ç®—æ³•ï¼Œåœ¨æ¯ä¸€æ­¥ä¿ç•™ K ä¸ªæœ€ä¼˜å€™é€‰åºåˆ—ï¼ˆbeamï¼‰ï¼Œ
    å¹³è¡¡æœç´¢è´¨é‡ä¸è®¡ç®—å¼€é”€ã€‚ä¸è´ªå¿ƒæœç´¢ï¼ˆåªä¿ç•™ 1 ä¸ªï¼‰ç›¸æ¯”ï¼Œèƒ½æ‰¾åˆ°æ›´ä¼˜çš„å…¨å±€è§£ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    # æ¨¡å‹é€‰æ‹©
    model_choice = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=list(DEMO_MODELS.keys()),
        help="é€‰æ‹©ç”¨äºæ¼”ç¤ºçš„æ¨¡å‹"
    )
    
    model_info = DEMO_MODELS[model_choice]
    
    with st.spinner(f"åŠ è½½ {model_choice}..."):
        model, tokenizer = load_model_and_tokenizer(model_info['id'])
    
    if model is None:
        st.error("æ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    st.success(f"âœ… æ¨¡å‹å·²åŠ è½½")
    
    st.markdown("---")
    
    # å‚æ•°è®¾ç½®
    col1, col2, col3 = st.columns(3)
    
    with col1:
        beam_size = st.slider(
            "Beam Size",
            min_value=2,
            max_value=5,
            value=3,
            help="æ¯æ­¥ä¿ç•™çš„å€™é€‰æ•°é‡"
        )
    
    with col2:
        max_steps = st.slider(
            "æœ€å¤§æ­¥æ•°",
            min_value=3,
            max_value=10,
            value=5,
            help="ç”Ÿæˆçš„æœ€å¤§ token æ•°"
        )
    
    with col3:
        st.metric("æœç´¢ç©ºé—´", f"{beam_size}^{max_steps} = {beam_size**max_steps}")
    
    # Prompt è¾“å…¥
    prompt = st.text_input(
        "è¾“å…¥ Prompt",
        value="Once upon a time",
        placeholder="è¾“å…¥èµ·å§‹æ–‡æœ¬..."
    )
    
    if st.button("å¼€å§‹ Beam Search", type="primary", width="stretch"):
        if not prompt:
            st.warning("è¯·è¾“å…¥ Prompt")
            return
        
        with st.spinner("æ‰§è¡Œ Beam Search..."):
            history = beam_search_with_history(
                model, tokenizer, prompt,
                beam_size=beam_size,
                max_steps=max_steps
            )
        
        # ç»“æœå±•ç¤º
        st.markdown("## æœç´¢ç»“æœ")
        
        # æœ€ç»ˆåºåˆ—
        st.markdown("### ğŸ† æœ€ç»ˆå€™é€‰åºåˆ—")
        
        for beam in history['final_beams']:
            rank_emoji = "ğŸ¥‡" if beam['rank'] == 1 else ("ğŸ¥ˆ" if beam['rank'] == 2 else "ğŸ¥‰")
            st.markdown(f"""
            <div style="background: linear-gradient(90deg, #DBEAFE, #F3F4F6); 
                        padding: 15px; border-radius: 8px; margin: 10px 0;">
                <span style="font-size: 20px;">{rank_emoji}</span>
                <b>Rank {beam['rank']}</b><br>
                <span style="font-family: monospace; font-size: 16px;">
                    {prompt}<b style="color: #2563EB;">{beam['sequence']}</b>
                </span><br>
                <small>ç´¯ç§¯ Log-Prob: {beam['score']:.4f} | 
                       æ¦‚ç‡: {beam['probability']:.2e}</small>
            </div>
            """, unsafe_allow_html=True)
        
        # æœç´¢æ ‘å¯è§†åŒ–
        st.markdown("### ğŸŒ³ æœç´¢æ ‘")
        fig = render_beam_tree(history)
        st.plotly_chart(fig, width='stretch')
        
        # é€æ­¥è¯¦æƒ…
        st.markdown("### ğŸ“‹ é€æ­¥è¯¦æƒ…")
        
        for step in history['steps']:
            with st.expander(f"Step {step['step'] + 1}", expanded=(step['step'] == 0)):
                render_step_detail(step)
        
        # åŸç†è¯´æ˜
        st.markdown("---")
        st.markdown("### ğŸ“š Beam Search åŸç†")
        
        col_a, col_b = st.columns(2)
        
        with col_a:
            st.markdown("""
            **ç®—æ³•æµç¨‹**:
            1. åˆå§‹åŒ– K ä¸ª beamï¼ˆåˆå§‹åªæœ‰ promptï¼‰
            2. å¯¹æ¯ä¸ª beamï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½çš„ä¸‹ä¸€ä¸ª token
            3. ä» K Ã— V ä¸ªå€™é€‰ä¸­é€‰æ‹© top-Kï¼ˆæŒ‰ç´¯ç§¯æ¦‚ç‡ï¼‰
            4. é‡å¤ç›´åˆ°è¾¾åˆ°æœ€å¤§é•¿åº¦æˆ–é‡åˆ° EOS
            
            **ç´¯ç§¯æ¦‚ç‡è®¡ç®—**:
            ```
            score(seq) = Î£ log P(t_i | t_<i)
            ```
            ä½¿ç”¨ log æ¦‚ç‡é¿å…æ•°å€¼ä¸‹æº¢ã€‚
            """)
        
        with col_b:
            st.markdown("""
            **å¯¹æ¯”å…¶ä»–ç­–ç•¥**:
            
            | ç­–ç•¥ | Beam Size | ç‰¹ç‚¹ |
            |------|-----------|------|
            | Greedy | 1 | å¿«ä½†æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ |
            | Beam Search | K | å¹³è¡¡è´¨é‡ä¸é€Ÿåº¦ |
            | Exhaustive | âˆ | æœ€ä¼˜ä½†è®¡ç®—é‡çˆ†ç‚¸ |
            
            **Length Penalty**:
            å®é™…åº”ç”¨ä¸­å¸¸åŠ å…¥é•¿åº¦æƒ©ç½šï¼š
            ```
            score = log_prob / length^Î±
            ```
            Î± > 1 åå¥½çŸ­åºåˆ—ï¼ŒÎ± < 1 åå¥½é•¿åºåˆ—
            """)

