"""
Config å·®å¼‚å¯¹æ¯” - å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„ config.json
"""

import streamlit as st
import json
from transformers import AutoConfig

# é¢„å®šä¹‰é…ç½®
PRESET_CONFIGS = {
    "Llama-2-7B": {
        "hidden_size": 4096, "num_hidden_layers": 32, "num_attention_heads": 32,
        "num_key_value_heads": 32, "intermediate_size": 11008,
        "max_position_embeddings": 4096, "rope_theta": 10000, "vocab_size": 32000
    },
    "Llama-3-8B": {
        "hidden_size": 4096, "num_hidden_layers": 32, "num_attention_heads": 32,
        "num_key_value_heads": 8, "intermediate_size": 14336,
        "max_position_embeddings": 8192, "rope_theta": 500000, "vocab_size": 128256
    },
    "Qwen-7B": {
        "hidden_size": 4096, "num_hidden_layers": 32, "num_attention_heads": 32,
        "num_key_value_heads": 32, "intermediate_size": 11008,
        "max_position_embeddings": 8192, "rope_theta": 10000, "vocab_size": 151936
    },
    "Mistral-7B": {
        "hidden_size": 4096, "num_hidden_layers": 32, "num_attention_heads": 32,
        "num_key_value_heads": 8, "intermediate_size": 14336,
        "max_position_embeddings": 32768, "rope_theta": 10000, "vocab_size": 32000,
        "sliding_window": 4096
    },
}

KEY_DESCRIPTIONS = {
    "hidden_size": "éšè—å±‚ç»´åº¦",
    "num_hidden_layers": "Transformer å±‚æ•°",
    "num_attention_heads": "æ³¨æ„åŠ›å¤´æ•° (Q)",
    "num_key_value_heads": "KV å¤´æ•° (GQA)",
    "intermediate_size": "FFN ä¸­é—´ç»´åº¦",
    "max_position_embeddings": "æœ€å¤§ä½ç½®ç¼–ç ",
    "rope_theta": "RoPE Base",
    "vocab_size": "è¯è¡¨å¤§å°",
    "sliding_window": "æ»‘åŠ¨çª—å£å¤§å°",
}


def render():
    """æ¸²æŸ“é¡µé¢"""
    st.markdown('<h1 class="module-title">Config å·®å¼‚å¯¹æ¯”</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="tip-box">
    ğŸ’¡ å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„æ¶æ„é…ç½®ï¼Œå¿«é€Ÿäº†è§£æ¨¡å‹æ¼”è¿›ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### æ¨¡å‹ A")
        model_a = st.selectbox("é€‰æ‹©æ¨¡å‹", list(PRESET_CONFIGS.keys()), key="model_a")
        config_a = PRESET_CONFIGS[model_a]
    
    with col2:
        st.markdown("### æ¨¡å‹ B")
        model_b = st.selectbox("é€‰æ‹©æ¨¡å‹", list(PRESET_CONFIGS.keys()), index=1, key="model_b")
        config_b = PRESET_CONFIGS[model_b]
    
    st.markdown("---")
    st.markdown("### ğŸ“Š é…ç½®å¯¹æ¯”")
    
    # æ”¶é›†æ‰€æœ‰ key
    all_keys = set(config_a.keys()) | set(config_b.keys())
    
    # æ„å»ºå¯¹æ¯”è¡¨
    diff_data = []
    for key in sorted(all_keys):
        val_a = config_a.get(key, "N/A")
        val_b = config_b.get(key, "N/A")
        
        # åˆ¤æ–­æ˜¯å¦æœ‰å·®å¼‚
        is_diff = val_a != val_b
        
        diff_data.append({
            "é…ç½®é¡¹": key,
            "è¯´æ˜": KEY_DESCRIPTIONS.get(key, ""),
            model_a: val_a,
            model_b: val_b,
            "å·®å¼‚": "âš ï¸" if is_diff else "âœ…"
        })
    
    # æ˜¾ç¤ºè¡¨æ ¼
    st.dataframe(diff_data, hide_index=True, width="stretch")
    
    # å…³é”®å·®å¼‚åˆ†æ
    st.markdown("### ğŸ” å…³é”®å·®å¼‚åˆ†æ")
    
    # GQA åˆ†æ
    gqa_a = config_a.get("num_key_value_heads", config_a.get("num_attention_heads"))
    gqa_b = config_b.get("num_key_value_heads", config_b.get("num_attention_heads"))
    heads_a = config_a.get("num_attention_heads", 32)
    heads_b = config_b.get("num_attention_heads", 32)
    
    col_a, col_b = st.columns(2)
    
    with col_a:
        st.markdown(f"**{model_a}**")
        if gqa_a == heads_a:
            st.info("ä½¿ç”¨ MHA (Multi-Head Attention)")
        else:
            st.success(f"ä½¿ç”¨ GQA, KV å¤´æ•°å‹ç¼© {heads_a // gqa_a}x")
    
    with col_b:
        st.markdown(f"**{model_b}**")
        if gqa_b == heads_b:
            st.info("ä½¿ç”¨ MHA (Multi-Head Attention)")
        else:
            st.success(f"ä½¿ç”¨ GQA, KV å¤´æ•°å‹ç¼© {heads_b // gqa_b}x")
    
    # RoPE åˆ†æ
    rope_a = config_a.get("rope_theta", 10000)
    rope_b = config_b.get("rope_theta", 10000)
    
    if rope_a != rope_b:
        st.markdown(f"""
        **RoPE Base å·®å¼‚**:
        - {model_a}: {rope_a:,}
        - {model_b}: {rope_b:,}
        - æ›´å¤§çš„ base æ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡å¤–æ¨
        """)
    
    # å‚æ•°é‡ä¼°ç®—
    st.markdown("---")
    st.markdown("### ğŸ“ å‚æ•°é‡ä¼°ç®—")
    
    def estimate_params(config):
        d = config['hidden_size']
        L = config['num_hidden_layers']
        V = config['vocab_size']
        ff = config['intermediate_size']
        
        # ç®€åŒ–ä¼°ç®—
        attention = 4 * d * d * L  # QKV + O
        ffn = 3 * d * ff * L  # gate, up, down
        embed = V * d
        
        return (attention + ffn + embed) / 1e9
    
    params_a = estimate_params(config_a)
    params_b = estimate_params(config_b)
    
    col_1, col_2 = st.columns(2)
    with col_1:
        st.metric(f"{model_a} ä¼°ç®—å‚æ•°", f"~{params_a:.1f}B")
    with col_2:
        st.metric(f"{model_b} ä¼°ç®—å‚æ•°", f"~{params_b:.1f}B")

