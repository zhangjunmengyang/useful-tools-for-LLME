"""
æ ¼å¼åŒ–è½¬æ¢å™¨ - SFT æ•°æ®æ ¼å¼è½¬æ¢
"""

import streamlit as st
import json
from data_lab.data_utils import CHAT_TEMPLATES, convert_to_format, validate_chat_format


def render():
    """æ¸²æŸ“é¡µé¢"""
    st.markdown('<h1 class="module-title">æ ¼å¼åŒ–è½¬æ¢å™¨</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="tip-box">
    ğŸ’¡ ä¸€é”®è½¬æ¢ SFT æ•°æ®æ ¼å¼ï¼Œæ”¯æŒ Alpacaã€ShareGPTã€ChatMLã€Llama-2 ç­‰ä¸»æµæ ¼å¼ã€‚
    </div>
    """, unsafe_allow_html=True)
    
    col_left, col_right = st.columns(2)
    
    with col_left:
        st.markdown("### è¾“å…¥æ•°æ®")
        
        input_json = st.text_area(
            "åŸå§‹ JSON",
            value='''{
    "instruction": "å°†ä»¥ä¸‹å¥å­ç¿»è¯‘æˆè‹±æ–‡",
    "input": "ä»Šå¤©å¤©æ°”çœŸå¥½",
    "output": "The weather is really nice today."
}''',
            height=200
        )
        
        # è§£æ JSON
        try:
            data = json.loads(input_json)
            st.success("âœ… JSON æ ¼å¼æ­£ç¡®")
        except json.JSONDecodeError as e:
            st.error(f"JSON æ ¼å¼é”™è¯¯: {e}")
            data = None
    
    with col_right:
        st.markdown("### è¾“å‡ºæ ¼å¼")
        
        target_format = st.selectbox(
            "ç›®æ ‡æ ¼å¼",
            options=list(CHAT_TEMPLATES.keys()),
            format_func=lambda x: CHAT_TEMPLATES[x]['name']
        )
        
        system_prompt = st.text_input(
            "System Prompt (å¯é€‰)",
            placeholder="è‡ªå®šä¹‰ system æç¤ºè¯"
        )
        
        if data:
            converted = convert_to_format(data, target_format, system_prompt)
            
            st.text_area("è½¬æ¢ç»“æœ", value=converted, height=200)
            
            # æ ¼å¼éªŒè¯
            validation = validate_chat_format(converted, target_format)
            if validation['valid']:
                st.success("âœ… æ ¼å¼éªŒè¯é€šè¿‡")
            else:
                st.warning("âš ï¸ æ ¼å¼é—®é¢˜:")
                for issue in validation['issues']:
                    st.caption(f"- {issue}")
    
    # æ ¼å¼è¯´æ˜
    st.markdown("---")
    st.markdown("### ğŸ“‹ æ ¼å¼è¯´æ˜")
    
    tab1, tab2, tab3, tab4 = st.tabs(["Alpaca", "ShareGPT", "ChatML", "Llama-2"])
    
    with tab1:
        st.code("""### Instruction:
{instruction}

### Input:
{input}

### Response:
{output}""", language="text")
    
    with tab2:
        st.code("""{
  "conversations": [
    {"from": "human", "value": "..."},
    {"from": "gpt", "value": "..."}
  ]
}""", language="json")
    
    with tab3:
        st.code("""<|im_start|>system
{system}<|im_end|>
<|im_start|>user
{user}<|im_end|>
<|im_start|>assistant
{assistant}<|im_end|>""", language="text")
    
    with tab4:
        st.code("""<s>[INST] <<SYS>>
{system}
<</SYS>>

{user} [/INST] {assistant} </s>""", language="text")
    
    st.markdown("""
    ### âš ï¸ å¸¸è§é—®é¢˜
    
    1. **EOS Token å¤„ç†**: ç¡®ä¿æ¯æ¡æ•°æ®ä»¥æ­£ç¡®çš„ EOS token ç»“å°¾
    2. **æ ‡ç­¾é—­åˆ**: ChatML/Llama æ ¼å¼éœ€è¦ä¸¥æ ¼çš„æ ‡ç­¾é—­åˆ
    3. **æŒ‡ä»¤æ³¨å…¥**: é¿å…ç”¨æˆ·è¾“å…¥åŒ…å«ç‰¹æ®Šæ ‡ç­¾å¯¼è‡´æ ¼å¼æ··ä¹±
    """)

