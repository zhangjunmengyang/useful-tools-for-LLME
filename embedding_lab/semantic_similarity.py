"""
Lab 4: è¯­ä¹‰ç›¸ä¼¼åº¦ - Token çº§çƒ­åŠ›å›¾ä¸å„å‘å¼‚æ€§åˆ†æ
"""

import streamlit as st
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from typing import List, Tuple

from embedding_lab.embedding_utils import (
    get_batch_embeddings,
    cosine_similarity,
    compute_anisotropy,
    whitening_transform,
    load_sentence_transformer
)


def tokenize_text(text: str) -> List[str]:
    """ç®€å•çš„ä¸­è‹±æ–‡åˆ†è¯"""
    import re
    
    # å…ˆæŒ‰ç©ºæ ¼åˆ†å‰²
    tokens = text.split()
    
    # å¯¹æ¯ä¸ªéƒ¨åˆ†è¿›ä¸€æ­¥å¤„ç†
    result = []
    for token in tokens:
        # å¦‚æœåŒ…å«ä¸­æ–‡ï¼Œé€å­—åˆ†å‰²
        if re.search(r'[\u4e00-\u9fff]', token):
            for char in token:
                if char.strip():
                    result.append(char)
        else:
            if token.strip():
                result.append(token)
    
    return result if result else [text]


def get_token_embeddings(text: str, model_name: str) -> Tuple[List[str], np.ndarray]:
    """è·å–æ–‡æœ¬ä¸­æ¯ä¸ª token çš„ embedding"""
    tokens = tokenize_text(text)
    
    if not tokens:
        return [], np.array([])
    
    embeddings = get_batch_embeddings(tokens, model_name)
    
    if embeddings is None:
        return tokens, np.array([])
    
    return tokens, embeddings


def create_similarity_heatmap(
    tokens_a: List[str],
    tokens_b: List[str],
    similarity_matrix: np.ndarray,
    text_a: str,
    text_b: str
) -> go.Figure:
    """åˆ›å»º Token-to-Token ç›¸ä¼¼åº¦çƒ­åŠ›å›¾"""
    
    fig = go.Figure(data=go.Heatmap(
        z=similarity_matrix,
        x=tokens_b,
        y=tokens_a,
        colorscale=[
            [0, '#F3F4F6'],      # ä½ç›¸ä¼¼åº¦ - æµ…ç°
            [0.3, '#DBEAFE'],    # ä¸­ä½ - æ·¡è“
            [0.5, '#93C5FD'],    # ä¸­ç­‰ - è“
            [0.7, '#3B82F6'],    # ä¸­é«˜ - æ·±è“
            [1, '#1D4ED8']       # é«˜ç›¸ä¼¼åº¦ - æœ€æ·±è“
        ],
        hovertemplate='<b>%{y}</b> â†” <b>%{x}</b><br>ç›¸ä¼¼åº¦: %{z:.4f}<extra></extra>',
        showscale=True,
        colorbar=dict(
            title=dict(text="ç›¸ä¼¼åº¦", font=dict(color='#111827')),
            tickfont=dict(color='#6B7280')
        )
    ))
    
    fig.update_layout(
        title=dict(
            text="Token-to-Token ç›¸ä¼¼åº¦çŸ©é˜µ",
            font=dict(size=16, color='#111827')
        ),
        xaxis=dict(
            title=f"æ–‡æœ¬ B: \"{text_b[:30]}...\"" if len(text_b) > 30 else f"æ–‡æœ¬ B: \"{text_b}\"",
            tickangle=-45,
            tickfont=dict(size=11, family='JetBrains Mono, monospace'),
            side='bottom'
        ),
        yaxis=dict(
            title=f"æ–‡æœ¬ A: \"{text_a[:30]}...\"" if len(text_a) > 30 else f"æ–‡æœ¬ A: \"{text_a}\"",
            tickfont=dict(size=11, family='JetBrains Mono, monospace'),
            autorange='reversed'
        ),
        plot_bgcolor='#FFFFFF',
        paper_bgcolor='#FFFFFF',
        font=dict(color='#111827', family='Inter, sans-serif'),
        height=max(400, len(tokens_a) * 25 + 150),
        margin=dict(l=100, r=40, t=60, b=100)
    )
    
    return fig


def create_anisotropy_visualization(
    similarities: List[float],
    mean_sim: float,
    std_sim: float,
    title: str = "è¯å¯¹ç›¸ä¼¼åº¦åˆ†å¸ƒ"
) -> go.Figure:
    """åˆ›å»ºå„å‘å¼‚æ€§å¯è§†åŒ–ï¼ˆç›¸ä¼¼åº¦åˆ†å¸ƒç›´æ–¹å›¾ï¼‰"""
    
    fig = go.Figure()
    
    # ç›´æ–¹å›¾ - æ·»åŠ æ›´å¥½çš„æ‚¬æµ®æç¤º
    fig.add_trace(go.Histogram(
        x=similarities,
        nbinsx=30,
        marker=dict(
            color='#3B82F6',
            line=dict(color='#1D4ED8', width=1)
        ),
        opacity=0.7,
        name='ç›¸ä¼¼åº¦åˆ†å¸ƒ',
        hovertemplate='<b>ç›¸ä¼¼åº¦åŒºé—´</b>: %{x:.2f}<br><b>è¯å¯¹æ•°é‡</b>: %{y} å¯¹<extra></extra>'
    ))
    
    # å¹³å‡å€¼çº¿
    fig.add_vline(
        x=mean_sim,
        line=dict(color='#DC2626', width=2, dash='dash'),
        annotation_text=f"å¹³å‡å€¼: {mean_sim:.3f}",
        annotation_position="top right",
        annotation_font=dict(size=12, color='#DC2626')
    )
    
    # ç†æƒ³å€¼å‚è€ƒçº¿ (0)
    fig.add_vline(
        x=0,
        line=dict(color='#059669', width=2, dash='dot'),
        annotation_text="ç†æƒ³å€¼: 0",
        annotation_position="bottom right",
        annotation_font=dict(size=11, color='#059669')
    )
    
    fig.update_layout(
        title=dict(
            text=title,
            font=dict(size=14, color='#111827')
        ),
        xaxis=dict(
            title="ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆè¶Šæ¥è¿‘ 0 è¶Šå¥½ï¼‰",
            range=[-0.3, 1.1],
            gridcolor='#E5E7EB',
            dtick=0.2
        ),
        yaxis=dict(
            title="è¯å¯¹æ•°é‡",
            gridcolor='#E5E7EB'
        ),
        plot_bgcolor='#FAFBFC',
        paper_bgcolor='#FFFFFF',
        font=dict(color='#111827', family='Inter, sans-serif'),
        height=320,
        showlegend=False,
        margin=dict(t=50, b=50)
    )
    
    return fig


def render():
    """æ¸²æŸ“ Lab 4: è¯­ä¹‰ç›¸ä¼¼åº¦ é¡µé¢"""
    st.markdown('<h1 class="module-title">è¯­ä¹‰ç›¸ä¼¼åº¦</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div style="background: linear-gradient(135deg, #FEE2E2 0%, #FEF3C7 100%); 
                border-radius: 8px; padding: 16px; margin-bottom: 24px; border: 1px solid #FECACA;">
        <p style="color: #991B1B; margin: 0; font-size: 14px;">
            <strong>ğŸ”¬ å¾®è§‚åˆ†æ</strong>ï¼šæ·±å…¥ç†è§£ç›¸ä¼¼åº¦è®¡ç®—çš„ç»†èŠ‚ã€‚<br/>
            Token çº§çƒ­åŠ›å›¾å±•ç¤ºè¯­ä¹‰å¯¹é½ï¼Œå„å‘å¼‚æ€§åˆ†ææ­ç¤ºå‘é‡ç©ºé—´çš„è´¨é‡ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Tab åˆ‡æ¢
    tab1, tab2 = st.tabs(["ğŸ“Š ç›¸ä¼¼åº¦çƒ­åŠ›å›¾", "ğŸ“ˆ å„å‘å¼‚æ€§åˆ†æ"])
    
    # ==================== Tab 1: ç›¸ä¼¼åº¦çƒ­åŠ›å›¾ ====================
    with tab1:
        st.markdown("### Token-to-Token ç›¸ä¼¼åº¦çŸ©é˜µ")
        
        st.markdown("""
        <div style="background: #F3F4F6; border-radius: 6px; padding: 12px; margin-bottom: 16px;">
            <p style="color: #4B5563; margin: 0; font-size: 13px;">
                è¾“å…¥ä¸¤æ®µæ–‡æœ¬ï¼ŒæŸ¥çœ‹å®ƒä»¬åœ¨ Token çº§åˆ«çš„è¯­ä¹‰å¯¹é½æƒ…å†µã€‚<br/>
                é¢œè‰²è¶Šæ·±è¡¨ç¤ºç›¸ä¼¼åº¦è¶Šé«˜ï¼Œå¯ç”¨äºåˆ†æåŒä¹‰è¯ã€è¯­åºå˜åŒ–ç­‰ã€‚
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        col_a, col_b = st.columns(2)
        
        with col_a:
            text_a = st.text_area(
                "æ–‡æœ¬ A",
                value="æˆ‘çœ‹è¿‡è¿™éƒ¨ç”µå½±",
                height=100,
                key="sim_text_a"
            )
        
        with col_b:
            text_b = st.text_area(
                "æ–‡æœ¬ B",
                value="è¿™ç‰‡å­æˆ‘çœ‹è¿‡",
                height=100,
                key="sim_text_b"
            )
        
        # é¢„è®¾æ¡ˆä¾‹
        st.markdown("#### é¢„è®¾æ¡ˆä¾‹")
        presets = [
            ("ğŸ”„ è¯­åºå˜åŒ–", "æˆ‘çœ‹è¿‡è¿™éƒ¨ç”µå½±", "è¿™ç‰‡å­æˆ‘çœ‹è¿‡"),
            ("ğŸ“– åŒä¹‰æ›¿æ¢", "æˆ‘éå¸¸å–œæ¬¢è¿™æœ¬ä¹¦", "æˆ‘ç‰¹åˆ«çˆ±è¿™æœ¬ä¹¦ç±"),
            ("ğŸŒ ä¸­è‹±å¯¹ç…§", "æˆ‘çˆ±ä½ ", "I love you"),
            ("âŒ æ— å…³æ–‡æœ¬", "ä»Šå¤©å¤©æ°”å¾ˆå¥½", "é‡å­åŠ›å­¦å¾ˆéš¾"),
        ]
        
        def set_sim_preset(a: str, b: str):
            """å›è°ƒå‡½æ•°ï¼šè®¾ç½®é¢„è®¾å€¼"""
            st.session_state.sim_text_a = a
            st.session_state.sim_text_b = b
        
        preset_cols = st.columns(len(presets))
        for i, (label, a, b) in enumerate(presets):
            with preset_cols[i]:
                st.button(
                    label, 
                    key=f"preset_sim_{i}", 
                    width="stretch",
                    on_click=set_sim_preset,
                    args=(a, b)
                )
        
        # æ¨¡å‹é€‰æ‹©
        model_name = st.selectbox(
            "Embedding æ¨¡å‹",
            options=[
                "paraphrase-multilingual-MiniLM-L12-v2",
                "all-MiniLM-L6-v2"
            ],
            format_func=lambda x: {
                "paraphrase-multilingual-MiniLM-L12-v2": "Multilingual MiniLM (æ¨è)",
                "all-MiniLM-L6-v2": "MiniLM-L6 (ä»…è‹±æ–‡)"
            }[x],
            key="sim_model"
        )
        
        if text_a and text_b:
            with st.spinner("è®¡ç®— Token Embeddings..."):
                tokens_a, emb_a = get_token_embeddings(text_a, model_name)
                tokens_b, emb_b = get_token_embeddings(text_b, model_name)
            
            if len(emb_a) == 0 or len(emb_b) == 0:
                st.error("Embedding è®¡ç®—å¤±è´¥")
            else:
                # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
                sim_matrix = np.zeros((len(tokens_a), len(tokens_b)))
                for i, ea in enumerate(emb_a):
                    for j, eb in enumerate(emb_b):
                        sim_matrix[i, j] = cosine_similarity(ea, eb)
                
                # åˆ›å»ºçƒ­åŠ›å›¾
                fig = create_similarity_heatmap(tokens_a, tokens_b, sim_matrix, text_a, text_b)
                st.plotly_chart(fig, width="stretch")
                
                # å¥å­çº§ç›¸ä¼¼åº¦
                st.markdown("---")
                
                full_emb_a = get_batch_embeddings([text_a], model_name)
                full_emb_b = get_batch_embeddings([text_b], model_name)
                
                if full_emb_a is not None and full_emb_b is not None:
                    sentence_sim = cosine_similarity(full_emb_a[0], full_emb_b[0])
                    
                    col_metric, col_insight = st.columns([1, 2])
                    
                    with col_metric:
                        st.metric("å¥å­çº§ç›¸ä¼¼åº¦", f"{sentence_sim:.4f}")
                    
                    with col_insight:
                        # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„ token å¯¹
                        max_idx = np.unravel_index(np.argmax(sim_matrix), sim_matrix.shape)
                        max_pair = (tokens_a[max_idx[0]], tokens_b[max_idx[1]])
                        max_sim = sim_matrix[max_idx]
                        
                        st.markdown(f"""
                        <div style="background: #D1FAE5; border-radius: 6px; padding: 12px;">
                            <p style="color: #065F46; margin: 0; font-size: 13px;">
                                <strong>æœ€å¼ºè¯­ä¹‰å¯¹é½</strong><br/>
                                ã€Œ{max_pair[0]}ã€â†”ã€Œ{max_pair[1]}ã€ç›¸ä¼¼åº¦: {max_sim:.4f}
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                
                # è§£é‡Šè¯´æ˜
                with st.expander("ğŸ’¡ å¦‚ä½•è§£è¯»çƒ­åŠ›å›¾"):
                    st.markdown("""
                    **çƒ­åŠ›å›¾åˆ†æè¦ç‚¹**ï¼š
                    
                    1. **å¯¹è§’çº¿é«˜äº®**ï¼šå¦‚æœä¸¤æ®µæ–‡æœ¬é¡ºåºä¸€è‡´ï¼Œç›¸ä¼¼çš„è¯ä¼šåœ¨å¯¹è§’çº¿ä¸Š
                    2. **äº¤å‰é«˜äº®**ï¼šè¯­åºå˜åŒ–æ—¶ï¼Œç›¸ä¼¼è¯ä¼šåœ¨éå¯¹è§’çº¿ä½ç½®é«˜äº®
                    3. **æ•´è¡Œ/æ•´åˆ—é«˜äº®**ï¼šæŸä¸ªè¯ä¸å¤šä¸ªè¯éƒ½ç›¸ä¼¼ï¼Œå¯èƒ½æ˜¯æ ¸å¿ƒè¯­ä¹‰è¯
                    4. **å…¨å±€åæš—**ï¼šä¸¤æ®µæ–‡æœ¬è¯­ä¹‰ä¸ç›¸å…³
                    
                    **é¢è¯•è€ƒç‚¹**ï¼š
                    - ä¸ºä»€ä¹ˆåŒä¹‰è¯èƒ½å¤Ÿå¯¹é½ï¼Ÿå› ä¸ºè®­ç»ƒæ—¶ç›¸ä¼¼ä¸Šä¸‹æ–‡ä¸­çš„è¯è·å¾—ç›¸ä¼¼å‘é‡
                    - è·¨è¯­è¨€å¯¹é½å¦‚ä½•å®ç°ï¼Ÿå¤šè¯­è¨€æ¨¡å‹åœ¨å¹³è¡Œè¯­æ–™ä¸Šè®­ç»ƒï¼Œå»ºç«‹è·¨è¯­è¨€è¯­ä¹‰ç©ºé—´
                    """)
    
    # ==================== Tab 2: å„å‘å¼‚æ€§åˆ†æ ====================
    with tab2:
        st.markdown("### å‘é‡ç©ºé—´å„å‘å¼‚æ€§åˆ†æ")
        
        st.markdown("""
**ğŸ¯ å®éªŒç›®çš„**ï¼šæ£€æµ‹ Embedding æ¨¡å‹çš„å‘é‡ç©ºé—´è´¨é‡

**ğŸ“Š å›¾è¡¨è§£è¯»**ï¼š
- ç›´æ–¹å›¾å±•ç¤ºæ‰€æœ‰**ä¸ç›¸å…³è¯å¯¹**çš„ç›¸ä¼¼åº¦åˆ†å¸ƒ
- **ç†æƒ³æƒ…å†µ**ï¼šä¸ç›¸å…³çš„è¯å¯¹ï¼Œç›¸ä¼¼åº¦åº”è¯¥æ¥è¿‘ **0**ï¼ˆç»¿è‰²è™šçº¿ï¼‰
- **å„å‘å¼‚æ€§é—®é¢˜**ï¼šå¦‚æœåˆ†å¸ƒåå³ï¼ˆå¹³å‡å€¼ > 0.3ï¼‰ï¼Œè¯´æ˜æ¨¡å‹å­˜åœ¨è´¨é‡é—®é¢˜
- **ç™½åŒ–å¤„ç†**ï¼šä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œå¯ä»¥ç¼“è§£å„å‘å¼‚æ€§é—®é¢˜
        """)
        
        st.markdown("---")
        
        # é€‰æ‹©åˆ†ææ–¹å¼
        analysis_mode = st.radio(
            "é€‰æ‹©è¯æ±‡æ¥æº",
            options=["ä½¿ç”¨é¢„ç½®è¯è¡¨", "ä½¿ç”¨è‡ªå®šä¹‰è¯æ±‡"],
            horizontal=True,
            key="aniso_mode"
        )
        
        # é¢„ç½®çš„ä¸ç›¸å…³è¯å¯¹
        preset_words = [
            "è‹¹æœ", "æ±½è½¦", "éŸ³ä¹", "ç”µè„‘", "å’–å•¡", "ä¹¦ç±", "å¤©ç©º", "æµ·æ´‹",
            "å±±å³°", "æ²³æµ", "åŸå¸‚", "å†œæ‘", "å†å²", "ç§‘å­¦", "è‰ºæœ¯", "ä½“è‚²",
            "æ”¿æ²»", "ç»æµ", "åŒ»å­¦", "æ³•å¾‹", "æ•™è‚²", "æ–‡åŒ–", "å®—æ•™", "å“²å­¦",
            "æ•°å­¦", "ç‰©ç†", "åŒ–å­¦", "ç”Ÿç‰©", "åœ°ç†", "å¿ƒç†", "ç¤¾ä¼š", "è¯­è¨€"
        ]
        
        if analysis_mode == "ä½¿ç”¨é¢„ç½®è¯è¡¨":
            texts_to_analyze = preset_words
            
            # å±•ç¤ºé¢„è®¾è¯è¡¨
            with st.expander(f"ğŸ“‹ æŸ¥çœ‹é¢„ç½®è¯è¡¨ï¼ˆ{len(preset_words)} ä¸ªè¯ï¼‰", expanded=False):
                # åˆ† 4 åˆ—å±•ç¤º
                cols = st.columns(4)
                for i, word in enumerate(preset_words):
                    cols[i % 4].markdown(f"`{word}`")
            
            n_pairs = len(texts_to_analyze) * (len(texts_to_analyze) - 1) // 2
            st.info(f"å°†è®¡ç®— {len(texts_to_analyze)} ä¸ªè¯æ±‡ä¹‹é—´çš„ **{n_pairs} ä¸ªè¯å¯¹**çš„ç›¸ä¼¼åº¦")
            
        else:
            st.markdown("""
ğŸ’¡ **ä½¿ç”¨è¯´æ˜**ï¼šè¾“å…¥ä¸€ç»„**è¯­ä¹‰ä¸ç›¸å…³**çš„è¯æ±‡ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ã€‚
ç†æƒ³æƒ…å†µä¸‹ï¼Œè¿™äº›è¯ä¸¤ä¸¤ä¹‹é—´çš„ç›¸ä¼¼åº¦åº”è¯¥æ¥è¿‘ 0ã€‚
            """)
            
            custom_words = st.text_area(
                "è¾“å…¥è¯æ±‡ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œå»ºè®® 10-50 ä¸ªä¸ç›¸å…³çš„è¯ï¼‰",
                value="è‹¹æœ\næ±½è½¦\néŸ³ä¹\nåŒ»ç”Ÿ\næ²³æµ\næ•°å­¦\nå’–å•¡\næ”¿æ²»\nè‰ºæœ¯\nåŒ–å­¦",
                height=150,
                key="aniso_custom"
            )
            texts_to_analyze = [w.strip() for w in custom_words.strip().split('\n') if w.strip()]
            
            if len(texts_to_analyze) >= 2:
                n_pairs = len(texts_to_analyze) * (len(texts_to_analyze) - 1) // 2
                st.caption(f"å½“å‰ {len(texts_to_analyze)} ä¸ªè¯ï¼Œå°†äº§ç”Ÿ {n_pairs} ä¸ªè¯å¯¹")
        
        # æ¨¡å‹é€‰æ‹©
        aniso_model = st.selectbox(
            "Embedding æ¨¡å‹",
            options=[
                "paraphrase-multilingual-MiniLM-L12-v2",
                "all-MiniLM-L6-v2"
            ],
            format_func=lambda x: {
                "paraphrase-multilingual-MiniLM-L12-v2": "Multilingual MiniLMï¼ˆæ¨èï¼Œæ”¯æŒä¸­æ–‡ï¼‰",
                "all-MiniLM-L6-v2": "MiniLM-L6ï¼ˆä»…è‹±æ–‡ï¼‰"
            }[x],
            key="aniso_model"
        )
        
        if st.button("ğŸ”¬ åˆ†æå„å‘å¼‚æ€§", type="primary", width="stretch"):
            if len(texts_to_analyze) < 5:
                st.warning("è‡³å°‘éœ€è¦ 5 ä¸ªè¯æ±‡æ‰èƒ½è¿›è¡Œæœ‰æ„ä¹‰çš„åˆ†æ")
            else:
                with st.spinner("è®¡ç®— Embeddings..."):
                    embeddings = get_batch_embeddings(texts_to_analyze, aniso_model)
                
                if embeddings is None:
                    st.error("Embedding è®¡ç®—å¤±è´¥")
                else:
                    # è®¡ç®—åŸå§‹å‘é‡çš„å„å‘å¼‚æ€§
                    mean_sim, std_sim = compute_anisotropy(embeddings, sample_size=min(100, len(embeddings)))
                    
                    # è®¡ç®—æ‰€æœ‰è¯å¯¹çš„ç›¸ä¼¼åº¦ï¼ŒåŒæ—¶è®°å½•è¯å¯¹ä¿¡æ¯
                    similarities = []
                    word_pairs = []
                    for i in range(len(embeddings)):
                        for j in range(i + 1, len(embeddings)):
                            sim = cosine_similarity(embeddings[i], embeddings[j])
                            similarities.append(sim)
                            word_pairs.append((texts_to_analyze[i], texts_to_analyze[j], sim))
                    
                    # æ’åºæ‰¾å‡ºæœ€ç›¸ä¼¼å’Œæœ€ä¸ç›¸ä¼¼çš„è¯å¯¹
                    word_pairs_sorted = sorted(word_pairs, key=lambda x: x[2], reverse=True)
                    
                    # æ˜¾ç¤ºè¯å¯¹ç¤ºä¾‹
                    st.markdown("#### ğŸ“ è¯å¯¹ç›¸ä¼¼åº¦ç¤ºä¾‹")
                    col_high, col_low = st.columns(2)
                    
                    with col_high:
                        st.markdown("**ç›¸ä¼¼åº¦æœ€é«˜çš„ 5 å¯¹**ï¼ˆå¯èƒ½æœ‰è¯­ä¹‰å…³è”ï¼‰")
                        for w1, w2, sim in word_pairs_sorted[:5]:
                            color = "#DC2626" if sim > 0.5 else "#D97706" if sim > 0.3 else "#059669"
                            st.markdown(f"- `{w1}` â†” `{w2}`: <span style='color:{color}'><b>{sim:.3f}</b></span>", unsafe_allow_html=True)
                    
                    with col_low:
                        st.markdown("**ç›¸ä¼¼åº¦æœ€ä½çš„ 5 å¯¹**ï¼ˆç¬¦åˆé¢„æœŸï¼‰")
                        for w1, w2, sim in word_pairs_sorted[-5:]:
                            color = "#059669" if sim < 0.2 else "#D97706"
                            st.markdown(f"- `{w1}` â†” `{w2}`: <span style='color:{color}'><b>{sim:.3f}</b></span>", unsafe_allow_html=True)
                    
                    st.markdown("---")
                    st.markdown("#### ğŸ“Š ç›¸ä¼¼åº¦åˆ†å¸ƒå¯¹æ¯”")
                    
                    col_original, col_whitened = st.columns(2)
                    
                    with col_original:
                        st.markdown("**åŸå§‹å‘é‡**")
                        
                        # æ˜¾ç¤ºæŒ‡æ ‡
                        metric_cols = st.columns(2)
                        metric_cols[0].metric("å¹³å‡ç›¸ä¼¼åº¦", f"{mean_sim:.4f}")
                        metric_cols[1].metric("æ ‡å‡†å·®", f"{std_sim:.4f}")
                        
                        # åˆ¤æ–­æ˜¯å¦å­˜åœ¨å„å‘å¼‚æ€§é—®é¢˜
                        if mean_sim > 0.3:
                            st.error("âš ï¸ å­˜åœ¨æ˜æ˜¾çš„å„å‘å¼‚æ€§é—®é¢˜ï¼ˆå¹³å‡å€¼ > 0.3ï¼‰")
                        elif mean_sim > 0.15:
                            st.warning("âš¡ å­˜åœ¨è½»å¾®çš„å„å‘å¼‚æ€§ï¼ˆå¹³å‡å€¼ > 0.15ï¼‰")
                        else:
                            st.success("âœ… å„å‘å¼‚æ€§ç¨‹åº¦è¾ƒä½ï¼Œå‘é‡ç©ºé—´è´¨é‡è‰¯å¥½")
                        
                        # ç»˜åˆ¶åˆ†å¸ƒå›¾
                        fig1 = create_anisotropy_visualization(
                            similarities, mean_sim, std_sim, 
                            title="åŸå§‹å‘é‡ - è¯å¯¹ç›¸ä¼¼åº¦åˆ†å¸ƒ"
                        )
                        st.plotly_chart(fig1, width="stretch")
                    
                    # ç™½åŒ–å¤„ç†
                    with col_whitened:
                        st.markdown("**ç™½åŒ–å¤„ç†å**")
                        
                        with st.spinner("æ‰§è¡Œç™½åŒ–å˜æ¢..."):
                            whitened = whitening_transform(embeddings)
                        
                        # è®¡ç®—ç™½åŒ–åçš„å„å‘å¼‚æ€§
                        mean_sim_w, std_sim_w = compute_anisotropy(whitened, sample_size=min(100, len(whitened)))
                        
                        # è®¡ç®—ç™½åŒ–åçš„ç›¸ä¼¼åº¦
                        similarities_w = []
                        for i in range(len(whitened)):
                            for j in range(i + 1, len(whitened)):
                                sim = cosine_similarity(whitened[i], whitened[j])
                                similarities_w.append(sim)
                        
                        metric_cols_w = st.columns(2)
                        delta_mean = mean_sim_w - mean_sim
                        delta_std = std_sim_w - std_sim
                        metric_cols_w[0].metric("å¹³å‡ç›¸ä¼¼åº¦", f"{mean_sim_w:.4f}", delta=f"{delta_mean:+.4f}")
                        metric_cols_w[1].metric("æ ‡å‡†å·®", f"{std_sim_w:.4f}", delta=f"{delta_std:+.4f}")
                        
                        if mean_sim_w < mean_sim * 0.8:
                            st.success(f"âœ… ç™½åŒ–æœ‰æ•ˆï¼å¹³å‡ç›¸ä¼¼åº¦é™ä½äº† {(1 - mean_sim_w/mean_sim)*100:.1f}%")
                        elif mean_sim_w < mean_sim:
                            st.info("ğŸ“‰ ç™½åŒ–æœ‰ä¸€å®šæ•ˆæœ")
                        else:
                            st.warning("âš ï¸ ç™½åŒ–æ•ˆæœä¸æ˜æ˜¾")
                        
                        fig2 = create_anisotropy_visualization(
                            similarities_w, mean_sim_w, std_sim_w,
                            title="ç™½åŒ–å - è¯å¯¹ç›¸ä¼¼åº¦åˆ†å¸ƒ"
                        )
                        st.plotly_chart(fig2, width="stretch")
                    
                    # è§£é‡Šè¯´æ˜
                    st.markdown("---")
                    with st.expander("ğŸ“š æ·±å…¥ç†è§£å„å‘å¼‚æ€§"):
                        st.markdown("""
                        **ä»€ä¹ˆæ˜¯å„å‘å¼‚æ€§ (Anisotropy)?**
                        
                        åœ¨ç†æƒ³çš„å‘é‡ç©ºé—´ä¸­ï¼Œéšæœºé€‰å–çš„ä¸¤ä¸ªä¸ç›¸å…³è¯æ±‡ï¼Œå®ƒä»¬çš„ä½™å¼¦ç›¸ä¼¼åº¦åº”è¯¥æ¥è¿‘ 0ã€‚
                        ä½†ç ”ç©¶å‘ç°ï¼Œå¾ˆå¤šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„è¯å‘é‡å­˜åœ¨ã€Œå„å‘å¼‚æ€§ã€é—®é¢˜ï¼š
                        - å‘é‡å€¾å‘äºå æ®é«˜ç»´ç©ºé—´çš„ä¸€ä¸ªç‹­çª„åœ†é”¥åŒºåŸŸ
                        - å¯¼è‡´å³ä½¿è¯­ä¹‰ä¸ç›¸å…³çš„è¯ï¼Œç›¸ä¼¼åº¦ä¹Ÿæ™®éåé«˜
                        
                        **ä¸ºä»€ä¹ˆè¿™æ˜¯é—®é¢˜?**
                        - é™ä½äº†ç›¸ä¼¼åº¦åˆ†æ•°çš„åŒºåˆ†åº¦
                        - å½±å“æ£€ç´¢ã€èšç±»ç­‰ä¸‹æ¸¸ä»»åŠ¡çš„æ•ˆæœ
                        
                        **è§£å†³æ–¹æ¡ˆ**:
                        1. **ç™½åŒ– (Whitening)**: å¯¹å‘é‡è¿›è¡Œçº¿æ€§å˜æ¢ï¼Œä½¿åæ–¹å·®çŸ©é˜µå˜ä¸ºå•ä½çŸ©é˜µ
                        2. **å¯¹æ¯”å­¦ä¹ **: ä½¿ç”¨ SimCSE ç­‰æ–¹æ³•å¾®è°ƒæ¨¡å‹
                        3. **åå¤„ç†**: å‡å»å¹³å‡å‘é‡ã€ä¸»æˆåˆ†ç§»é™¤ç­‰
                        
                        **é¢è¯•è€ƒç‚¹**:
                        - å„å‘å¼‚æ€§çš„æˆå› ï¼šè®­ç»ƒç›®æ ‡ï¼ˆå¦‚ MLMï¼‰å¯¼è‡´å‘é‡èšé›†
                        - ç™½åŒ–çš„æ•°å­¦åŸç†ï¼šåæ–¹å·®çŸ©é˜µç‰¹å¾å€¼åˆ†è§£
                        - æƒè¡¡ï¼šç™½åŒ–å¯èƒ½ä¸¢å¤±éƒ¨åˆ†è¯­ä¹‰ä¿¡æ¯
                        """)

